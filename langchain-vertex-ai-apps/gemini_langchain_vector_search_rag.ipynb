{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d711a135-52de-4287-9259-ab3abf4c3744",
   "metadata": {},
   "source": [
    "# Build a Knowledge Based System with Vertex AI Vector Search, LangChain and Gemini\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Generate embeddings for a dataset\n",
    "2. Add the embeddings to Cloud Storage\n",
    "3. Create an index in Vertex AI Vector Search\n",
    "4. Leverage similarity metrics to evaluate and retrieve the most relevant knowledge base results\n",
    "5. Utilize LangChain to query Vertex AI Vector Search and provide context to prompts submitted to Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af38e44-2867-4c6b-93a7-642aa86f9c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "!pip3 install -q --upgrade pip\n",
    "!pip3 install -q google-cloud-aiplatform\n",
    "!pip3 install -q langchain\n",
    "!pip3 install -q langchain-community\n",
    "!pip3 install -q lxml\n",
    "!pip3 install -q requests\n",
    "!pip3 install -q beautifulsoup4\n",
    "!pip3 install -q unstructured\n",
    "!pip3 install -q langchain-google-genai\n",
    "!pip3 install -q google-generativeai\n",
    "!pip3 install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b371c287-5c4d-4f6d-9483-787ddb7a79c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart the kernel\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac7c23-8831-4594-a9aa-a1aade9da542",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f13fb6-6a06-4dcb-9812-4643cb1f9cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import textwrap\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d754a634-726f-4e04-bbec-ff241cfbdb74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source API key from GCP project and configure genai client\n",
    "import os\n",
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "key_name = !gcloud services api-keys list --filter=\"gemini-api-key\" --format=\"value(name)\"\n",
    "key_name = key_name[0]\n",
    "\n",
    "api_key = !gcloud services api-keys get-key-string $key_name --location=\"us-central1\" --format=\"value(keyString)\"\n",
    "api_key = api_key[0]\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db35058-5ee4-4eda-94d1-1c8fa96235fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your project ID is: qwiklabs-gcp-02-2cb5b7451de0\n"
     ]
    }
   ],
   "source": [
    "# Define project information\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "PROJECT_ID = subprocess.check_output([\"gcloud\", \"config\", \"get-value\", \"project\"], text=True).strip()\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "print(f\"Your project ID is: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9781195e-7ab6-455b-9397-e166352bfb09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set environment vars\n",
    "BUCKET = f\"gs://{PROJECT_ID}/embeddings\"\n",
    "DIMENSIONS=768\n",
    "DISPLAY_NAME='vertex_docs_qa'\n",
    "ENDPOINT=f\"{REGION}-aiplatform.googleapis.com\"\n",
    "TEXT_GENERATION_MODEL='gemini-pro'\n",
    "SITEMAP='https://docs.anthropic.com/sitemap.xml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c15d201b-404b-4fbb-8ff2-7e45096ab2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f243a82-fb52-4874-a921-978a5a2769c4",
   "metadata": {},
   "source": [
    "# Create Documents from Vertex AI Cloud Documentation Site\n",
    "\n",
    "## Load and parse sitemap.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6c90bd-1d13-4b5b-baaa-9d17b6097b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse the xml of sitemap and get URLs of doc site\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_sitemap(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"xml\")\n",
    "    urls = [element.text for element in soup.find_all(\"loc\")]\n",
    "    return urls\n",
    "\n",
    "sites = parse_sitemap(SITEMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a375b356-263c-481a-89eb-19eeacbf2088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use this to filter out docs that don't have a corresponding reference page\n",
    "sites_filtered = [url for url in sites if '/en/docs' in url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c956153-9c15-42b2-83fc-6c30c13d21c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sites_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc151f1f-0416-4421-909d-b792750220d2",
   "metadata": {},
   "source": [
    "## Load documentation pages using the LangChain UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82632343-60bd-4c3c-a39d-ae728f75d1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This step will take a few minutes to complete\n",
    "# you will see download messages below the cell after execution\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "loader = UnstructuredURLLoader(urls=sites_filtered)\n",
    "documents = loader.load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d537a9e4-85e1-44c8-9c91-fd32bc527566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Anthropic home page\n",
       "> \n",
       "> Use cases\n",
       "> \n",
       "> Content moderation\n",
       "> \n",
       "> WelcomeUser GuidesAPI ReferencePrompt LibraryRelease NotesDeveloper Newsletter\n",
       "> \n",
       "> Developer Console\n",
       "> \n",
       "> Developer Discord\n",
       "> \n",
       "> Support\n",
       "> \n",
       "> Get started\n",
       "> \n",
       "> Overview\n",
       "> \n",
       "> Initial setup\n",
       "> \n",
       "> Intro to Claude\n",
       "> \n",
       "> Learn about Claude\n",
       "> \n",
       "> Use cases\n",
       "> \n",
       "> Overview\n",
       "> \n",
       "> Ticket routing\n",
       "> \n",
       "> Customer support agent\n",
       "> \n",
       "> Content moderation\n",
       "> \n",
       "> Legal summarization\n",
       "> \n",
       "> Models\n",
       "> \n",
       "> Security and compliance\n",
       "> \n",
       "> Build with Claude\n",
       "> \n",
       "> Define success criteria\n",
       "> \n",
       "> Develop test cases\n",
       "> \n",
       "> Prompt engineering\n",
       "> \n",
       "> Text generation\n",
       "> \n",
       "> Embeddings\n",
       "> \n",
       "> Google Sheets add-on\n",
       "> \n",
       "> Vision\n",
       "> \n",
       "> Tool use (function calling)\n",
       "> \n",
       "> Prompt Caching (beta)\n",
       "> \n",
       "> Message Batches (beta)\n",
       "> \n",
       "> Test and evaluate\n",
       "> \n",
       "> Strengthen guardrails\n",
       "> \n",
       "> Using the Evaluation Tool\n",
       "> \n",
       "> Resources\n",
       "> \n",
       "> Glossary\n",
       "> \n",
       "> Model Deprecations\n",
       "> \n",
       "> System status\n",
       "> \n",
       "> Claude 3 model card\n",
       "> \n",
       "> Anthropic Cookbook\n",
       "> \n",
       "> Anthropic Courses\n",
       "> \n",
       "> Legal center\n",
       "> \n",
       "> Anthropic Privacy Policy\n",
       "> \n",
       "> Use cases\n",
       "> \n",
       "> Content moderation\n",
       "> \n",
       "> Content moderation is a critical aspect of maintaining a safe, respectful, and productive environment in digital applications. In this guide, we’ll discuss how Claude can be used to moderate content within your digital application.\n",
       "> \n",
       "> Visit our content moderation cookbook to see an example content moderation implementation using Claude.\n",
       "> \n",
       "> This guide is focused on moderating user-generated content within your application. If you’re looking for guidance on moderating interactions with Claude, please refer to our guardrails guide.\n",
       "> \n",
       "> Before building with Claude\n",
       "> \n",
       "> Decide whether to use Claude for content moderation\n",
       "> \n",
       "> Here are some key indicators that you should use an LLM like Claude instead of a traditional ML or rules-based approach for content moderation:\n",
       "> \n",
       "> Traditional ML methods require significant engineering resources, ML expertise, and infrastructure costs. Human moderation systems incur even higher costs. With Claude, you can have a sophisticated moderation system up and running in a fraction of the time for a fraction of the price.\n",
       "> \n",
       "> Traditional ML approaches, such as bag-of-words models or simple pattern matching, often struggle to understand the tone, intent, and context of the content. While human moderation systems excel at understanding semantic meaning, they require time for content to be reviewed. Claude bridges the gap by combining semantic understanding with the ability to deliver moderation decisions quickly.\n",
       "> \n",
       "> By leveraging its advanced reasoning capabilities, Claude can interpret and apply complex moderation guidelines uniformly. This consistency helps ensure fair treatment of all content, reducing the risk of inconsistent or biased moderation decisions that can undermine user trust.\n",
       "> \n",
       "> Once a traditional ML approach has been established, changing it is a laborious and data-intensive undertaking. On the other hand, as your product or customer needs evolve, Claude can easily adapt to changes or additions to moderation policies without extensive relabeling of training data.\n",
       "> \n",
       "> If you wish to provide users or regulators with clear explanations behind moderation decisions, Claude can generate detailed and coherent justifications. This transparency is important for building trust and ensuring accountability in content moderation practices.\n",
       "> \n",
       "> Traditional ML approaches typically require separate models or extensive translation processes for each supported language. Human moderation requires hiring a workforce fluent in each supported language. Claude’s multilingual capabilities allow it to classify tickets in various languages without the need for separate models or extensive translation processes, streamlining moderation for global customer bases.\n",
       "> \n",
       "> Claude’s multimodal capabilities allow it to analyze and interpret content across both text and images. This makes it a versatile tool for comprehensive content moderation in environments where different media types need to be evaluated together.\n",
       "> \n",
       "> Anthropic has trained all Claude models to be honest, helpful and harmless. This may result in Claude moderating content deemed particularly dangerous (in line with our Acceptable Use Policy), regardless of the prompt used. For example, an adult website that wants to allow users to post explicit sexual content may find that Claude still flags explicit content as requiring moderation, even if they specify in their prompt not to moderate explicit sexual content. We recommend reviewing our AUP in advance of building a moderation solution.\n",
       "> \n",
       "> Generate examples of content to moderate\n",
       "> \n",
       "> Before developing a content moderation solution, first create examples of content that should be flagged and content that should not be flagged. Ensure that you include edge cases and challenging scenarios that may be difficult for a content moderation system to handle effectively. Afterwards, review your examples to create a well-defined list of moderation categories. For instance, the examples generated by a social media platform might include the following:\n",
       "> \n",
       "> allowed_user_comments = [\n",
       ">     'This movie was great, I really enjoyed it. The main actor really killed it!',\n",
       ">     'I hate Mondays.',\n",
       ">     'It is a great time to invest in gold!'\n",
       "> ]\n",
       "> \n",
       "> disallowed_user_comments = [\n",
       ">     'Delete this post now or you better hide. I am coming after you and your family.',\n",
       ">     'Stay away from the 5G cellphones!! They are using 5G to control you.',\n",
       ">     'Congratulations! You have won a $1,000 gift card. Click here to claim your prize!'\n",
       "> ]\n",
       "> \n",
       "> # Sample user comments to test the content moderation\n",
       "> user_comments = allowed_user_comments + disallowed_user_comments\n",
       "> \n",
       "> # List of categories considered unsafe for content moderation\n",
       "> unsafe_categories = [\n",
       ">     'Child Exploitation',\n",
       ">     'Conspiracy Theories',\n",
       ">     'Hate',\n",
       ">     'Indiscriminate Weapons', \n",
       ">     'Intellectual Property',\n",
       ">     'Non-Violent Crimes', \n",
       ">     'Privacy',\n",
       ">     'Self-Harm',\n",
       ">     'Sex Crimes',\n",
       ">     'Sexual Content',\n",
       ">     'Specialized Advice',\n",
       ">     'Violent Crimes'\n",
       "> ]\n",
       "> \n",
       "> Effectively moderating these examples requires a nuanced understanding of language. In the comment, This movie was great, I really enjoyed it. The main actor really killed it!, the content moderation system needs to recognize that “killed it” is a metaphor, not an indication of actual violence. Conversely, despite the lack of explicit mentions of violence, the comment Delete this post now or you better hide. I am coming after you and your family. should be flagged by the content moderation system.\n",
       "> \n",
       "> The unsafe_categories list can be customized to fit your specific needs. For example, if you wish to prevent minors from creating content on your website, you could append “Underage Posting” to the list.\n",
       "> \n",
       "> How to moderate content using Claude\n",
       "> \n",
       "> Select the right Claude model\n",
       "> \n",
       "> When selecting a model, it’s important to consider the size of your data. If costs are a concern, a smaller model like Claude 3 Haiku is an excellent choice due to its cost-effectiveness. Below is an estimate of the cost to moderate text for a social media platform that receives one billion posts per month:\n",
       "> \n",
       "> Content size\n",
       "> \n",
       "> Posts per month: 1bn\n",
       "> \n",
       "> Characters per post: 100\n",
       "> \n",
       "> Total characters: 100bn\n",
       "> \n",
       "> Estimated tokens\n",
       "> \n",
       "> Input tokens: 28.6bn (assuming 1 token per 3.5 characters)\n",
       "> \n",
       "> Percentage of messages flagged: 3%\n",
       "> \n",
       "> Output tokens per flagged message: 50\n",
       "> \n",
       "> Total output tokens: 1.5bn\n",
       "> \n",
       "> Claude 3 Haiku estimated cost\n",
       "> \n",
       "> Input token cost: 2,860 MTok * $0.25/MTok = $715\n",
       "> \n",
       "> Output token cost: 1,500 MTok * $1.25/MTok = $1,875\n",
       "> \n",
       "> Monthly cost: $715 + $1,875 = $2,590\n",
       "> \n",
       "> Claude 3.5 Sonnet estimated cost\n",
       "> \n",
       "> Input token cost: 2,860 MTok * $3.00/MTok = $8,580\n",
       "> \n",
       "> Output token cost: 1,500 MTok * $15.00/MTok = $22,500\n",
       "> \n",
       "> Monthly cost: $8,580 + $22,500 = $31,080\n",
       "> \n",
       "> Actual costs may differ from these estimates. These estimates are based on the prompt highlighted in the section on batch processing. Output tokens can be reduced even further by removing the explanation field from the response.\n",
       "> \n",
       "> Build a strong prompt\n",
       "> \n",
       "> In order to use Claude for content moderation, Claude must understand the moderation requirements of your application. Let’s start by writing a prompt that allows you to define your moderation needs:\n",
       "> \n",
       "> import anthropic\n",
       "> import json\n",
       "> \n",
       "> # Initialize the Anthropic client\n",
       "> client = anthropic.Anthropic()\n",
       "> \n",
       "> def moderate_message(message, unsafe_categories):\n",
       ">     # Convert the list of unsafe categories into a string, with each category on a new line\n",
       ">     unsafe_category_str = '\\n'.join(unsafe_categories)\n",
       ">     \n",
       ">     # Construct the prompt for Claude, including the message and unsafe categories\n",
       ">     assessment_prompt = f\"\"\"\n",
       ">     Determine whether the following message warrants moderation, \n",
       ">     based on the unsafe categories outlined below.\n",
       ">     \n",
       ">     Message:\n",
       ">     <message>{message}</message>\n",
       "> \n",
       ">     Unsafe Categories:\n",
       ">     <categories>\n",
       ">     {unsafe_category_str}\n",
       ">     </categories>\n",
       "> \n",
       ">     Respond with ONLY a JSON object, using the format below:\n",
       ">     {{\n",
       ">     \"violation\": <Boolean field denoting whether the message should be moderated>,\n",
       ">     \"categories\": [Comma-separated list of violated categories],\n",
       ">     \"explanation\": [Optional. Only include if there is a violation.]\n",
       ">     }}\"\"\"\n",
       "> \n",
       ">     # Send the request to Claude for content moderation\n",
       ">     response = client.messages.create(\n",
       ">         model=\"claude-3-haiku-20240307\",  # Using the Haiku model for lower costs\n",
       ">         max_tokens=200,\n",
       ">         temperature=0,   # Use 0 temperature for increased consistency\n",
       ">         messages=[\n",
       ">             {\"role\": \"user\", \"content\": assessment_prompt}\n",
       ">         ]\n",
       ">     )\n",
       ">     \n",
       ">     # Parse the JSON response from Claude\n",
       ">     assessment = json.loads(response.content[0].text)\n",
       ">     \n",
       ">     # Extract the violation status from the assessment\n",
       ">     contains_violation = assessment['violation']\n",
       ">     \n",
       ">     # If there's a violation, get the categories and explanation; otherwise, use empty defaults\n",
       ">     violated_categories = assessment.get('categories', []) if contains_violation else []\n",
       ">     explanation = assessment.get('explanation') if contains_violation else None\n",
       ">     \n",
       ">     return contains_violation, violated_categories, explanation\n",
       "> \n",
       "> # Process each comment and print the results\n",
       "> for comment in user_comments:\n",
       ">     print(f\"\\nComment: {comment}\")\n",
       ">     violation, violated_categories, explanation = moderate_message(comment, unsafe_categories)\n",
       ">     \n",
       ">     if violation:\n",
       ">         print(f\"Violated Categories: {', '.join(violated_categories)}\")\n",
       ">         print(f\"Explanation: {explanation}\")\n",
       ">     else:\n",
       ">         print(\"No issues detected.\")\n",
       "> \n",
       "> In this example, the moderate_message function contains an assessment prompt that includes the unsafe content categories and the message we wish to evaluate. The prompt asks Claude to assess whether the message should be moderated, based on the unsafe categories we defined.\n",
       "> \n",
       "> The model’s assessment is then parsed to determine if there is a violation. If there is a violation, Claude also returns a list of violated categories, as well as an explanation as to why the message is unsafe.\n",
       "> \n",
       "> Evaluate your prompt\n",
       "> \n",
       "> Content moderation is a classification problem. Thus, you can use the same techniques outlined in our classification cookbook to determine the accuracy of your content moderation system.\n",
       "> \n",
       "> One additional consideration is that instead of treating content moderation as a binary classification problem, you may instead create multiple categories to represent various risk levels. Creating multiple risk levels allows you to adjust the aggressiveness of your moderation. For example, you might want to automatically block user queries that are deemed high risk, while users with many medium risk queries are flagged for human review.\n",
       "> \n",
       "> import anthropic\n",
       "> import json\n",
       "> \n",
       "> # Initialize the Anthropic client\n",
       "> client = anthropic.Anthropic()\n",
       "> \n",
       "> def assess_risk_level(message, unsafe_categories):\n",
       ">     # Convert the list of unsafe categories into a string, with each category on a new line\n",
       ">     unsafe_category_str = '\\n'.join(unsafe_categories)\n",
       ">     \n",
       ">     # Construct the prompt for Claude, including the message, unsafe categories, and risk level definitions\n",
       ">     assessment_prompt = f\"\"\"\n",
       ">     Assess the risk level of the following message warrants moderation, \n",
       ">     based on the unsafe categories listed below.\n",
       ">     \n",
       "> Message:\n",
       "> <message>{message}</message>\n",
       "> \n",
       "> Unsafe Categories:\n",
       "> <categories>\n",
       "> {unsafe_category_str}\n",
       "> </categories>\n",
       "> \n",
       "> Assign a risk level based on your confidence that the user's message should be moderated \n",
       "> based on the defined unsafe categories:\n",
       "> \n",
       "> 0 - No risk\n",
       "> 1 - Low risk\n",
       "> 2 - Medium risk\n",
       "> 3 - High risk\n",
       "> \n",
       "> Respond with ONLY a JSON object, using the format below:\n",
       "> {{\n",
       ">   \"risk_level\": <Numerical field denoting the risk level>,\n",
       ">   \"categories\": [Comma-separated list of violated categories],\n",
       ">   \"explanation\": <Optional. Only include if risk level is greater than 0>\n",
       "> }}\"\"\"\n",
       "> \n",
       ">     # Send the request to Claude for risk assessment\n",
       ">     response = client.messages.create(\n",
       ">         model=\"claude-3-haiku-20240307\",  # Using the Haiku model for lower costs\n",
       ">         max_tokens=200,\n",
       ">         temperature=0,   # Use 0 temperature for increased consistency\n",
       ">         messages=[\n",
       ">             {\"role\": \"user\", \"content\": assessment_prompt}\n",
       ">         ]\n",
       ">     )\n",
       ">     \n",
       ">     # Parse the JSON response from Claude\n",
       ">     assessment = json.loads(response.content[0].text)\n",
       ">     \n",
       ">     # Extract the risk level, violated categories, and explanation from the assessment\n",
       ">     risk_level = assessment[\"risk_level\"]\n",
       ">     violated_categories = assessment[\"categories\"]\n",
       ">     explanation = assessment.get(\"explanation\")\n",
       ">     \n",
       ">     return risk_level, violated_categories, explanation\n",
       "> \n",
       "> # Process each comment and print the results\n",
       "> for comment in user_comments:\n",
       ">     print(f\"\\nComment: {comment}\")\n",
       ">     risk_level, violated_categories, explanation = assess_risk_level(comment, unsafe_categories)\n",
       ">     \n",
       ">     print(f\"Risk Level: {risk_level}\")\n",
       ">     if violated_categories:\n",
       ">         print(f\"Violated Categories: {', '.join(violated_categories)}\")\n",
       ">     if explanation:\n",
       ">         print(f\"Explanation: {explanation}\")\n",
       "> \n",
       "> This code implements an assess_risk_level function that uses Claude to evaluate the risk level of a message. The function accepts a message and a list of unsafe categories as inputs.\n",
       "> \n",
       "> Within the function, a prompt is generated for Claude, including the message to be assessed, the unsafe categories, and specific instructions for evaluating the risk level. The prompt instructs Claude to respond with a JSON object that includes the risk level, the violated categories, and an optional explanation.\n",
       "> \n",
       "> This approach enables flexible content moderation by assigning risk levels. It can be seamlessly integrated into a larger system to automate content filtering or flag comments for human review based on their assessed risk level. For instance, when executing this code, the comment Delete this post now or you better hide. I am coming after you and your family. is identified as high risk due to its dangerous threat. Conversely, the comment Stay away from the 5G cellphones!! They are using 5G to control you. is categorized as medium risk.\n",
       "> \n",
       "> Deploy your prompt\n",
       "> \n",
       "> Once you are confident in the quality of your solution, it’s time to deploy it to production. Here are some best practices to follow when using content moderation in production:\n",
       "> \n",
       "> Provide clear feedback to users: When user input is blocked or a response is flagged due to content moderation, provide informative and constructive feedback to help users understand why their message was flagged and how they can rephrase it appropriately. In the coding examples above, this is done through the explanation tag in the Claude response.\n",
       "> \n",
       "> Analyze moderated content: Keep track of the types of content being flagged by your moderation system to identify trends and potential areas for improvement.\n",
       "> \n",
       "> Continuously evaluate and improve: Regularly assess the performance of your content moderation system using metrics such as precision and recall tracking. Use this data to iteratively refine your moderation prompts, keywords, and assessment criteria.\n",
       "> \n",
       "> Improve performance\n",
       "> \n",
       "> In complex scenarios, it may be helpful to consider additional strategies to improve performance beyond standard prompt engineering techniques. Here are some advanced strategies:\n",
       "> \n",
       "> Define topics and provide examples\n",
       "> \n",
       "> In addition to listing the unsafe categories in the prompt, further improvements can be made by providing definitions and phrases related to each category.\n",
       "> \n",
       "> import anthropic\n",
       "> import json\n",
       "> \n",
       "> # Initialize the Anthropic client\n",
       "> client = anthropic.Anthropic()\n",
       "> \n",
       "> # Dictionary of categories considered unsafe for content moderation, with their definitions\n",
       "> unsafe_category_definitions = {\n",
       ">     'Child Exploitation': 'Content that depicts child nudity or that enables, encourages, excuses, or depicts the sexual abuse of children.',\n",
       ">     'Conspiracy Theories': \"\"\"Content that promotes or endorses unfounded, false, or misleading theories about events, situations, or individuals, \n",
       ">         which can incite harm or undermine public trust in institutions or facts.\"\"\",\n",
       ">     'Hate': \"\"\"Content that is hateful toward people on the basis of their protected characteristics \n",
       ">         (race, color, ethnicity, national origin, disability, religious affiliation, caste, sexual orientation, sex, gender identity and serious disease), \n",
       ">         or content that perpetuates negative stereotypes.\"\"\",\n",
       ">     'Indiscriminate Weapons': 'Content that enables the creation of weapons of mass destruction.', \n",
       ">     'Intellectual Property': 'Content that violates the intellectual property rights of third parties.',\n",
       ">     'Non-Violent Crimes': 'Content that enables, encourages, or excuses the commission of non-violent crimes.', \n",
       ">     'Privacy': 'Content that contains sensitive, personal information about private individuals.',\n",
       ">     'Self-Harm': 'Content that enables, encourages, or excuses acts of intentional self-harm.',\n",
       ">     'Sex Crimes': 'Content that enables, encourages, or excuses the commission of sex crimes.',\n",
       ">     'Sexual Content': 'Content that contains erotic descriptions or explicit depictions of sex acts.',\n",
       ">     'Specialized Advice': \"\"\"Content that contains financial, medical, or legal advice. \n",
       ">         Financial advice includes guidance on investments, stocks, bonds, or any financial planning.\"\"\",\n",
       ">     'Violent Crimes': 'Content that enables, encourages, or excuses the commission of violent crimes.', \n",
       "> }\n",
       "> \n",
       "> \n",
       "> def moderate_message_with_definitions(message, unsafe_category_definitions):\n",
       ">     # Format unsafe categories string, with each category and its definition on a new line\n",
       ">     unsafe_category_str = '\\n'.join(f'{category}: {definition}' \n",
       ">         for category, definition in unsafe_category_definitions.items()\n",
       ">     )\n",
       ">     \n",
       ">     # Construct the prompt for Claude, including the message and unsafe categories\n",
       ">     assessment_prompt = f\"\"\"Determine whether the following message warrants moderation, based on the unsafe categories outlined below.\n",
       "> \n",
       "> Message:\n",
       "> <message>{message}</message>\n",
       "> \n",
       "> Unsafe Categories and Their Definitions:\n",
       "> <categories>\n",
       "> {unsafe_category_str}\n",
       "> </categories>\n",
       "> \n",
       "> It's important that you remember all unsafe categories and their definitions.\n",
       "> \n",
       "> Respond with ONLY a JSON object, using the format below:\n",
       "> {{\n",
       ">   \"violation\": <Boolean field denoting whether the message should be moderated>,\n",
       ">   \"categories\": [Comma-separated list of violated categories],\n",
       ">   \"explanation\": [Optional. Only include if there is a violation.]\n",
       "> }}\"\"\"\n",
       "> \n",
       ">     # Send the request to Claude for content moderation\n",
       ">     response = client.messages.create(\n",
       ">         model=\"claude-3-haiku-20240307\",  # Using the Haiku model for lower costs\n",
       ">         max_tokens=200,\n",
       ">         temperature=0,   # Use 0 temperature for increased consistency\n",
       ">         messages=[\n",
       ">             {\"role\": \"user\", \"content\": assessment_prompt}\n",
       ">         ]\n",
       ">     )\n",
       ">     \n",
       ">     # Parse the JSON response from Claude\n",
       ">     assessment = json.loads(response.content[0].text)\n",
       ">     \n",
       ">     # Extract the violation status from the assessment\n",
       ">     contains_violation = assessment['violation']\n",
       ">     \n",
       ">     # If there's a violation, get the categories and explanation; otherwise, use empty defaults\n",
       ">     violated_categories = assessment.get('categories', []) if contains_violation else []\n",
       ">     explanation = assessment.get('explanation') if contains_violation else None\n",
       ">     \n",
       ">     return contains_violation, violated_categories, explanation\n",
       "> \n",
       "> \n",
       "> # Process each comment and print the results\n",
       "> for comment in user_comments:\n",
       ">     print(f\"\\nComment: {comment}\")\n",
       ">     violation, violated_categories, explanation = moderate_message_with_definitions(comment, unsafe_category_definitions)\n",
       ">     \n",
       ">     if violation:\n",
       ">         print(f\"Violated Categories: {', '.join(violated_categories)}\")\n",
       ">         print(f\"Explanation: {explanation}\")\n",
       ">     else:\n",
       ">         print(\"No issues detected.\")\n",
       "> \n",
       "> The moderate_message_with_definitions function expands upon the earlier moderate_message function by allowing each unsafe category to be paired with a detailed definition. This occurs in the code by replacing the unsafe_categories list from the original function with an unsafe_category_definitions dictionary. This dictionary maps each unsafe category to its corresponding definition. Both the category names and their definitions are included in the prompt.\n",
       "> \n",
       "> Notably, the definition for the Specialized Advice category now specifies the types of financial advice that should be prohibited. As a result, the comment It's a great time to invest in gold!, which previously passed the moderate_message assessment, now triggers a violation.\n",
       "> \n",
       "> Consider batch processing\n",
       "> \n",
       "> To reduce costs in situations where real-time moderation isn’t necessary, consider moderating messages in batches. Include multiple messages within the prompt’s context, and ask Claude to assess which messages should be moderated.\n",
       "> \n",
       "> import anthropic\n",
       "> import json\n",
       "> \n",
       "> # Initialize the Anthropic client\n",
       "> client = anthropic.Anthropic()\n",
       "> \n",
       "> def batch_moderate_messages(messages, unsafe_categories):\n",
       ">     # Convert the list of unsafe categories into a string, with each category on a new line\n",
       ">     unsafe_category_str = '\\n'.join(unsafe_categories)\n",
       ">     \n",
       ">     # Format messages string, with each message wrapped in XML-like tags and given an ID\n",
       ">     messages_str = '\\n'.join([f'<message id={idx}>{msg}</message>' for idx, msg in enumerate(messages)])\n",
       ">     \n",
       ">     # Construct the prompt for Claude, including the messages and unsafe categories\n",
       ">     assessment_prompt = f\"\"\"Determine the messages to moderate, based on the unsafe categories outlined below.\n",
       "> \n",
       "> Messages:\n",
       "> <messages>\n",
       "> {messages_str}\n",
       "> </messages>\n",
       "> \n",
       "> Unsafe categories and their definitions:\n",
       "> <categories>\n",
       "> {unsafe_category_str}\n",
       "> </categories>\n",
       "> \n",
       "> Respond with ONLY a JSON object, using the format below:\n",
       "> {{\n",
       ">   \"violations\": [\n",
       ">     {{\n",
       ">       \"id\": <message id>,\n",
       ">       \"categories\": [list of violated categories],\n",
       ">       \"explanation\": <Explanation of why there's a violation>\n",
       ">     }},\n",
       ">     ...\n",
       ">   ]\n",
       "> }}\n",
       "> \n",
       "> Important Notes:\n",
       "> - Remember to analyze every message for a violation.\n",
       "> - Select any number of violations that reasonably apply.\"\"\"\n",
       "> \n",
       ">     # Send the request to Claude for content moderation\n",
       ">     response = client.messages.create(\n",
       ">         model=\"claude-3-haiku-20240307\",  # Using the Haiku model for lower costs\n",
       ">         max_tokens=2048,  # Increased max token count to handle batches\n",
       ">         temperature=0,    # Use 0 temperature for increased consistency\n",
       ">         messages=[\n",
       ">             {\"role\": \"user\", \"content\": assessment_prompt}\n",
       ">         ]\n",
       ">     )\n",
       ">     \n",
       ">     # Parse the JSON response from Claude\n",
       ">     assessment = json.loads(response.content[0].text)\n",
       ">     return assessment\n",
       "> \n",
       "> \n",
       "> # Process the batch of comments and get the response\n",
       "> response_obj = batch_moderate_messages(user_comments, unsafe_categories)\n",
       "> \n",
       "> # Print the results for each detected violation\n",
       "> for violation in response_obj['violations']:\n",
       ">     print(f\"\"\"Comment: {user_comments[violation['id']]}\n",
       "> Violated Categories: {', '.join(violation['categories'])}\n",
       "> Explanation: {violation['explanation']}\n",
       "> \"\"\")\n",
       "> \n",
       "> In this example, the batch_moderate_messages function handles the moderation of an entire batch of messages with a single Claude API call. Inside the function, a prompt is created that includes the list of messages to evaluate, the defined unsafe content categories, and their descriptions. The prompt directs Claude to return a JSON object listing all messages that contain violations. Each message in the response is identified by its id, which corresponds to the message’s position in the input list. Keep in mind that finding the optimal batch size for your specific needs may require some experimentation. While larger batch sizes can lower costs, they might also lead to a slight decrease in quality. Additionally, you may need to increase the max_tokens parameter in the Claude API call to accommodate longer responses. For details on the maximum number of tokens your chosen model can output, refer to the model comparison page.\n",
       "> \n",
       "> Content moderation cookbook\n",
       "> \n",
       "> View a fully implemented code-based example of how to use Claude for content moderation.\n",
       "> \n",
       "> Guardrails guide\n",
       "> \n",
       "> Explore our guardrails guide for techniques to moderate interactions with Claude.\n",
       "> \n",
       "> Customer support agentLegal summarization\n",
       "> \n",
       "> xlinkedin\n",
       "> \n",
       "> On this page\n",
       "> \n",
       "> Before building with Claude\n",
       "> \n",
       "> Decide whether to use Claude for content moderation\n",
       "> \n",
       "> Generate examples of content to moderate\n",
       "> \n",
       "> How to moderate content using Claude\n",
       "> \n",
       "> Select the right Claude model\n",
       "> \n",
       "> Build a strong prompt\n",
       "> \n",
       "> Evaluate your prompt\n",
       "> \n",
       "> Deploy your prompt\n",
       "> \n",
       "> Improve performance\n",
       "> \n",
       "> Define topics and provide examples\n",
       "> \n",
       "> Consider batch processing\n",
       "> \n",
       "> Source: https://docs.anthropic.com/en/docs/about-claude/use-case-guides/content-moderation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(documents[1].page_content + \"\\n\\nSource: \" + documents[1].metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cacb3e49-cd62-4043-9440-5013eb1797b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f00b5-4022-467e-a001-008b8a53768c",
   "metadata": {},
   "source": [
    "## Create Document chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eccee30-c90b-4243-a445-53950364b3c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number documents 37\n",
      "Number chunks 238\n"
     ]
    }
   ],
   "source": [
    "# recursively loop through the text and create document chunks for embedding\n",
    "import warnings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    #separator = \"\\n\",\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 100)\n",
    "\n",
    "document_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Number documents {len(documents)}\")\n",
    "print(f\"Number chunks {len(document_chunks)}\")\n",
    "\n",
    "document_chunks=[f\"content: {chunk.page_content}, source: {chunk.metadata['source']}\" for chunk in document_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7387e-11df-4d72-9fb0-dda3acc098d8",
   "metadata": {},
   "source": [
    "# Generate embeddings from Document chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b57362bd-7e38-445c-ada9-20e57132bbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a documents directory\n",
    "!rm -rf ./documents\n",
    "!mkdir ./documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bc6e60a-aa97-4553-a50d-58649e84df60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content: Anthropic home page\\n\\nLearn about Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content: Model Anthropic API AWS Bedrock GCP V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content: Prompt and output performance\\n\\nThe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>content: Claude 2.1 Claude 2 Claude Instant 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>content: xlinkedin\\n\\nOn this page\\n\\nModel na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>content: Set appropriate output limits: Use th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>content: Anthropic home page\\n\\nStrengthen gua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>content: Strategies to reduce prompt leak\\n\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>content: Anthropic home page\\n\\nGet started\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>content: Key capabilities\\n\\nClaude can assist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    content: Anthropic home page\\n\\nLearn about Cl...\n",
       "1    content: Model Anthropic API AWS Bedrock GCP V...\n",
       "2    content: Prompt and output performance\\n\\nThe ...\n",
       "3    content: Claude 2.1 Claude 2 Claude Instant 1....\n",
       "4    content: xlinkedin\\n\\nOn this page\\n\\nModel na...\n",
       "..                                                 ...\n",
       "233  content: Set appropriate output limits: Use th...\n",
       "234  content: Anthropic home page\\n\\nStrengthen gua...\n",
       "235  content: Strategies to reduce prompt leak\\n\\nS...\n",
       "236  content: Anthropic home page\\n\\nGet started\\n\\...\n",
       "237  content: Key capabilities\\n\\nClaude can assist...\n",
       "\n",
       "[238 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the document chunks in a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(document_chunks, columns =['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba0a5ff-26a5-4023-b833-fb9f9b418a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:32<00:00,  7.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to generate the embeddings files you will later upload to Cloud Storage\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "index_embeddings = []\n",
    "model = \"models/embedding-001\"\n",
    "\n",
    "for index, doc in tqdm(df.iterrows(), total=len(df), position=0):\n",
    "\n",
    "    response = genai.embed_content(model=model, content=doc['text'], task_type=\"retrieval_query\")\n",
    "\n",
    "    doc_id=f\"{index}.txt\"\n",
    "    embedding_dict = {\n",
    "        \"id\": doc_id,\n",
    "        \"embedding\": response[\"embedding\"],\n",
    "    }\n",
    "    index_embeddings.append(json.dumps(embedding_dict) + \"\\n\")\n",
    "    \n",
    "    with open(f\"documents/{doc_id}\", \"w\") as document:\n",
    "          document.write(doc['text'])\n",
    "    \n",
    "with open(\"embeddings.json\", \"w\") as f:\n",
    "    f.writelines(index_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93913e92-4c3f-46cc-9498-cde46fe559f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "source_file = '/home/jupyter/embeddings.json'\n",
    "destination_blob_name = 'embeddings/embeddings.json' # Adjust if needed\n",
    "\n",
    "client = storage.Client(project=PROJECT_ID)\n",
    "bucket = client.bucket(PROJECT_ID)\n",
    "blob = bucket.blob(destination_blob_name)\n",
    "blob.upload_from_filename(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa9c1278-41f3-4892-bd7d-a9d6eb7848c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['gsutil', '-q', 'cp', '-r', './documents', 'gs://qwiklabs-gcp-02-2cb5b7451de0/documents'], returncode=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the embedding files to Cloud Storage\n",
    "# This step will take a few minutes to complete\n",
    "import subprocess\n",
    "gsutil_command = f\"gsutil -q cp -r './documents' gs://{PROJECT_ID}/documents\"\n",
    "\n",
    "subprocess.run(['gsutil', '-q', 'cp', '-r', './documents', f'gs://{PROJECT_ID}/documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056208e-7570-4005-b274-90e62d539fb9",
   "metadata": {},
   "source": [
    "# Create a Vertex AI Vector Store index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7566d26d-d5eb-4774-80a3-dc61b570fd93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/201377065835/locations/us-central1/indexes/4250953845540126720/operations/6531253722171834368\n",
      "MatchingEngineIndex created. Resource name: projects/201377065835/locations/us-central1/indexes/4250953845540126720\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/201377065835/locations/us-central1/indexes/4250953845540126720')\n"
     ]
    }
   ],
   "source": [
    "# Create the Vertex AI Vector Search index\n",
    "# This step will take several minutes to complete\n",
    "# Wait for this cell to complete before proceeding\n",
    "index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "      display_name=\"vertex_docs\",\n",
    "      contents_delta_uri=f\"gs://{PROJECT_ID}/embeddings\",\n",
    "      dimensions=768,\n",
    "      approximate_neighbors_count=150,\n",
    "      distance_measure_type=\"DOT_PRODUCT_DISTANCE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ced8d73-3b98-4e55-89ca-a29bcb086d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/201377065835/locations/us-central1/indexEndpoints/4627074783169740800/operations/7358227203747741696\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/201377065835/locations/us-central1/indexEndpoints/4627074783169740800\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/201377065835/locations/us-central1/indexEndpoints/4627074783169740800')\n"
     ]
    }
   ],
   "source": [
    "index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=\"vertex_docs\",\n",
    "    description=\"Embeddings for the documentation curated from the sitemap.\",\n",
    "    public_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b42d4077-275f-43cf-8c55-993e0880d651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/201377065835/locations/us-central1/indexEndpoints/4627074783169740800\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/201377065835/locations/us-central1/indexEndpoints/4627074783169740800/operations/1568286932809547776\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/201377065835/locations/us-central1/indexEndpoints/4627074783169740800\n"
     ]
    }
   ],
   "source": [
    "# This step will take up to 20 minutes to complete\n",
    "# You can view the deployment in the Vertex AI console on the \"Vector Search\" tab\n",
    "# Wait for this cell to complete before proceeding\n",
    "index_endpoint = index_endpoint.deploy_index(\n",
    "    index=index, deployed_index_id=\"vertex_index_deployment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "877608b4-9496-48c5-8513-799d6324f3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[index_endpoint: \"projects/201377065835/locations/us-central1/indexEndpoints/4627074783169740800\"\n",
       "deployed_index_id: \"vertex_index_deployment\"\n",
       "]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_RESOURCE_NAME=index.resource_name\n",
    "index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)\n",
    "\n",
    "deployed_index = index.deployed_indexes\n",
    "deployed_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a81baa-a4f6-4712-8db2-339b3ca74e35",
   "metadata": {},
   "source": [
    "# Search Vector Store, add result as context to a query (without using a LangChain Chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9f563bb-4417-4eac-b675-2377e151357d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In the next cells you will query the model directly using the Vertex AI python SDK\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores.matching_engine import MatchingEngine\n",
    "from langchain.agents import Tool\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "def search_vector_store(question):\n",
    "\n",
    "    vector_store = MatchingEngine.from_components(\n",
    "                        index_id=INDEX_RESOURCE_NAME,\n",
    "                        region=REGION,\n",
    "                        embedding=embeddings,\n",
    "                        project_id=PROJECT_ID,\n",
    "                        endpoint_id=deployed_index[0].index_endpoint,\n",
    "                        gcs_bucket_name=f\"{PROJECT_ID}\")\n",
    "    \n",
    "    relevant_documentation=vector_store.similarity_search(question, k=8)\n",
    "    context = \"\\n\".join([doc.page_content for doc in relevant_documentation])[:10000]\n",
    "    return str(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42442602-f577-4cb2-b4a9-e26fa2425cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "import warnings\n",
    "\n",
    "# filter warnings for unused libs\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def ask_question(question):\n",
    "    context = search_vector_store(question)\n",
    "\n",
    "    prompt=f\"\"\"\n",
    "        Follow exactly those 3 steps:\n",
    "        1. Read the context below and aggregrate this data\n",
    "        Context : {context}\n",
    "        2. Answer the question using only this context\n",
    "        3. Show the source for your answers\n",
    "        User Question: {question}\n",
    "\n",
    "\n",
    "        If you don't have any context and are unsure of the answer, reply that you don't know about this topic.\n",
    "        \"\"\"\n",
    "\n",
    "    model = GenerativeModel(\"gemini-pro\")\n",
    "    response = model.generate_content(prompt)\n",
    "\n",
    "    return to_markdown(f\"Question: \\n{question} \\n\\n Response: \\n {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61376c0e-0447-4527-b212-e65f6b128fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Question: \n",
       "> How do I reduce prompt leaks? \n",
       "> \n",
       ">  Response: \n",
       ">  You can try using system prompts to isolate key information and context from user queries. You can emphasize key instructions in the User turn, then reemphasize those instructions by prefilling the Assistant turn.\n",
       "> \n",
       "> Notice that this system prompt is still predominantly a role prompt, which is the most effective way to use system prompts."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(\"How do I reduce prompt leaks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edef10e5-28ab-49f1-bc35-a783ef03e572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Question: \n",
       "> What use cases and capabilities does Anthropic support? \n",
       "> \n",
       ">  Response: \n",
       ">  ## Anthropic's Use Cases and Capabilities:\n",
       "> \n",
       "> **Use Cases:**\n",
       "> \n",
       "> * **Customer Support Agent:** Claude can handle customer inquiries in real time, 24/7, reducing wait times and managing high volumes of support queries.\n",
       "> * **Content Moderation:** Claude can identify and remove harmful or inappropriate content from online platforms.\n",
       "> * **Legal Summarization:** Claude can summarize legal documents and contracts, saving time and effort for lawyers and legal professionals.\n",
       "> * **Ticket Routing:** Claude can automatically route customer support tickets to the appropriate agent based on the content of the message.\n",
       "> \n",
       "> **Capabilities:**\n",
       "> \n",
       "> * **Text Generation:** Claude can generate human-quality text in response to prompts and questions.\n",
       "> * **Reasoning and Math:** Claude can solve complex reasoning and math problems.\n",
       "> * **Vision:** Claude can understand and analyze images.\n",
       "> * **Tool Use (Function Calling):** Claude can be integrated with other applications and tools to automate tasks.\n",
       "> * **Embeddings:** Claude can generate numerical representations of text that can be used for tasks like similarity search and classification.\n",
       "> * **Coding:** Claude can generate and debug code in multiple programming languages.\n",
       "> * **Large Language Model (LLM):** Claude is a large language model that has been trained on a massive dataset of text and code. This allows Claude to perform a wide range of tasks, including language translation, writing different kinds of creative content, and answering open ended, challenging, or strange questions.\n",
       "> \n",
       "> **Source:**\n",
       "> \n",
       "> This information is aggregated from the provided context:\n",
       "> \n",
       "> * https://docs.anthropic.com/en/docs/intro-to-claude\n",
       "> * https://docs.anthropic.com/en/docs/about-claude/use-case-guides/customer-support-chat\n",
       "> * https://docs.anthropic.com/en/docs/build-with-claude/vision\n",
       "> * https://docs.anthropic.com/en/docs/welcome-to-claude\n",
       "> * https://docs.anthropic.com/en/docs/intro-to-claude/overview"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(\"What use cases and capabilities does Anthropic support?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730748e8-587d-4a07-b707-9f945e6ec96a",
   "metadata": {},
   "source": [
    "# Create Retrieval Augmentation Generation application using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bf0e958-9d7b-44f0-8893-a508250fa836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To answer questions and chain together the prompt, vector search, returned context and model input use a LangChain \"Chain\"\n",
    "# In this case you will use the RetrievalQA chain which is commonly used for Question/Answering applications\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# initialize model using chat\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.0, convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e2d89b2-7cab-4b72-ab2c-c0c931c777ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "    Follow exactly those 3 steps:\n",
    "    1. Read the context below and aggregrate this data\n",
    "    Context : {context}\n",
    "    \n",
    "    2. Answer the question using only this context\n",
    "    3. Show the source for your answers\n",
    "    User Question: {question}\n",
    "\n",
    "    If you don't have any context and are unsure of the answer, reply that you don't know about this topic.\n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"context\",  \"question\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4576213f-c4f0-4603-9ffb-5f4692f425e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> content: Use Workbench to create evals, draft prompts, and iteratively refine based on test results.\n",
       "> \n",
       "> Deploy polished prompts and monitor real-world performance for further refinement.\n",
       "> \n",
       "> Implement Claude\n",
       "> \n",
       "> Set up your environment, integrate Claude with your systems (APIs, databases, UIs), and define human-in-the-loop requirements.\n",
       "> \n",
       "> Test your system\n",
       "> \n",
       "> Conduct red teaming for potential misuse and A/B test improvements.\n",
       "> \n",
       "> Deploy to production\n",
       "> \n",
       "> Once your application runs smoothly end-to-end, deploy to production.\n",
       "> \n",
       "> Monitor and improve\n",
       "> \n",
       "> Monitor performance and effectiveness to make ongoing improvements.\n",
       "> \n",
       "> Start building with Claude\n",
       "> \n",
       "> When you’re ready, start building with Claude:\n",
       "> \n",
       "> Follow the Quickstart to make your first API call\n",
       "> \n",
       "> Check out the API Reference\n",
       "> \n",
       "> Explore the Prompt Library for example prompts\n",
       "> \n",
       "> Experiment and start building with the Workbench\n",
       "> \n",
       "> Check out the Anthropic Cookbook for working code examples\n",
       "> \n",
       "> Initial setupOverview\n",
       "> \n",
       "> xlinkedin\n",
       "> \n",
       "> On this page\n",
       "> \n",
       "> What you can do with Claude\n",
       "> \n",
       "> Model options\n",
       "> \n",
       "> Claude 3.5 Family\n",
       "> \n",
       "> Claude 3 Family\n",
       "> \n",
       "> Enterprise considerations\n",
       "> \n",
       "> Implementing Claude\n",
       "> \n",
       "> Start building with Claude, source: https://docs.anthropic.com/en/docs/intro-to-claude"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores.matching_engine import MatchingEngine\n",
    "\n",
    "vector_store = MatchingEngine.from_components(\n",
    "    index_id=INDEX_RESOURCE_NAME,\n",
    "    region=REGION,\n",
    "    embedding=embeddings,\n",
    "    project_id=PROJECT_ID,\n",
    "    endpoint_id=deployed_index[0].index_endpoint,\n",
    "    gcs_bucket_name=f\"{PROJECT_ID}\"\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs={'k': 1}\n",
    ")\n",
    "\n",
    "# Test the retriever with a simple search performed above\n",
    "to_markdown(retriever.get_relevant_documents(\"How do I get started with Anthropic?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4caa14bf-0cab-4955-8fb2-d44682c52756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b756d95c-fe7f-4eaa-b1c7-0fa6f3fb5187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_question(question: str):\n",
    "    response = qa({\"query\": question})\n",
    "\n",
    "    # since k is set to 1 only return the first source retrieved\n",
    "    source = response['source_documents']\n",
    "    \n",
    "    return to_markdown(f\"Response: \\n\\n {response['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b220d283-bf02-4a4b-9975-dc3d0a4c2b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Response: \n",
       "> \n",
       ">  1. Follow the Quickstart to make your first API call\n",
       "> 2. Check out the API Reference\n",
       "> 3. Explore the Prompt Library for example prompts\n",
       "> 4. Experiment and start building with the Workbench\n",
       "> 5. Check out the Anthropic Cookbook for working code examples\n",
       "> \n",
       "> Source: https://docs.anthropic.com/en/docs/intro-to-claude"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: You will see a library warning when running this step\n",
    "ask_question(\"How do I get started with Anthropic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfd393-c8db-4706-b8ff-e7ff2e79e6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0905e420-9f07-4b49-abba-be823f4ff542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b29c87-659f-4d1e-8f5f-129846a76b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-17.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-17:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
