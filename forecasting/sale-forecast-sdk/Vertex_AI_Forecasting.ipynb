{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHLV0D7Y5jtU"
   },
   "source": [
    "# Vertex AI SDK for Python: Vertex AI Forecasting Model Training \n",
    "\n",
    "This notebook demonstrates how to create an AutoML model using the SDK based on a time series dataset. \n",
    "\n",
    "To use this notebook run each step, or cell, in seuqence and see its results. To run a cell, use Shift+Enter. The notebooks will automatically display the return value of the last line in each cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lld3eeJUs5yM"
   },
   "source": [
    "# Install Vertex AI SDK, create a storage bucket and define envrionment variables\n",
    "\n",
    "After the SDK installation the kernel will be automatically restarted. You may see this error message `Your session crashed for an unknown reason` which is normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the Vertex AI SDK and restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMZLb8Arr2AG"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 uninstall -y google-cloud-aiplatform\n",
    "!pip3 install google-cloud-aiplatform\n",
    " \n",
    "import IPython\n",
    " \n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python system modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ApsLDJjdsGPN"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Lab Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwlVqT6RKxG7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "print(\"Project ID: \", PROJECT_ID)\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET_NAME = \"gs://\"+PROJECT_ID\n",
    "REGION = \"us-central1\"  # Change this if you need to use a different region for Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFfpJs3DQsfo"
   },
   "source": [
    "## Create a Regional Storage Bucket\n",
    "\n",
    "This cell creates a new regional Cloud Storage bucket for the lab. This bucket uses the lab Project_ID to ensure that it is a unique name across all Cloud Storage buckets.\n",
    "\n",
    "You cannot use a Multi-Regional Cloud Storage bucket for training with Vertex AI, you must use a Regional Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqSQT6Z6bekX"
   },
   "outputs": [],
   "source": [
    "!gsutil mb -l {REGION} {BUCKET_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6AQjKlnx0mf"
   },
   "source": [
    "## Define Training Dataset source\n",
    "\n",
    "The datasets you are using are samples from the [Iowa Liquor Retail Sales](https://pantheon.corp.google.com/marketplace/product/iowa-department-of-commerce/iowa-liquor-sales) dataset. The training sample contains the sales from 2020 and the prediction sample (used in the batch prediction step) contains the January - April sales from 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_T10yTTqcS_"
   },
   "outputs": [],
   "source": [
    "TRAINING_DATASET_BQ_PATH = 'bq://bigquery-public-data:iowa_liquor_sales_forecasting.2020_sales_train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rk43VP_IqcTE"
   },
   "source": [
    "# Initialize Vertex AI SDK\n",
    "\n",
    "Initialize the *client* for Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCiC9gBWqcTF"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35QVNhACqcTJ"
   },
   "source": [
    "# Create a Managed Time Series Dataset from BigQuery\n",
    "\n",
    "This section will create a dataset from a BigQuery table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OfCqaYRqcTJ"
   },
   "outputs": [],
   "source": [
    "ds = aiplatform.datasets.TimeSeriesDataset.create(\n",
    "    display_name='iowa_liquor_sales_train',\n",
    "    bq_source=[TRAINING_DATASET_BQ_PATH])\n",
    "\n",
    "ds.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-bBqipfqcTS"
   },
   "source": [
    "# Create a Training Job to train a Vertex AI Forecasting Model\n",
    "\n",
    "You create the Vertex AI AutoML Forecasting job definition , specifying the optimization objective and any column transformations required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aA41rT_mb-rV"
   },
   "outputs": [],
   "source": [
    "time_column = \"date\"\n",
    "time_series_identifier_column=\"store_name\"\n",
    "target_column=\"sale_dollars\"\n",
    "\n",
    "job = aiplatform.AutoMLForecastingTrainingJob(\n",
    "    display_name='train-iowa-liquor-sales-automl_1',\n",
    "    optimization_objective='minimize-rmse',    \n",
    "    column_transformations=[\n",
    "        {\"timestamp\": {\"column_name\": time_column}},\n",
    "        {\"numeric\": {\"column_name\": target_column}},\n",
    "        {\"categorical\": {\"column_name\": \"city\"}},\n",
    "        {\"categorical\": {\"column_name\": \"zip_code\"}},\n",
    "        {\"categorical\": {\"column_name\": \"county\"}},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Vertex AI AutoML Forecasting model\n",
    "\n",
    "You now run the training job to train the Vertex AI AutoML Forecasting model. \n",
    "\n",
    "**Note:** This will take approximately an hour and 15 minutes to run.\n",
    "\n",
    "While you are waiting for this to complete you can return to the lab guide for instructions on how to download and explore sample batch prediction output data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = job.run(\n",
    "    dataset=ds,\n",
    "    target_column=target_column,\n",
    "    time_column=time_column,\n",
    "    time_series_identifier_column=time_series_identifier_column,\n",
    "    available_at_forecast_columns=[time_column],\n",
    "    unavailable_at_forecast_columns=[target_column],\n",
    "    time_series_attribute_columns=[\"city\", \"zip_code\", \"county\"],\n",
    "    forecast_horizon=30,\n",
    "    context_window=30,\n",
    "    data_granularity_unit=\"day\",\n",
    "    data_granularity_count=1,\n",
    "    weight_column=None,\n",
    "    budget_milli_node_hours=1000,\n",
    "    model_display_name=\"iowa-liquor-sales-forecast-model\", \n",
    "    predefined_split_column_name=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Model Evaluation Metrics\n",
    "\n",
    "Fetch the model evaluation metrics calculated during training on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "muSC-mvgHno7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_evaluation_pager = model.api_client.list_model_evaluations(parent=model.resource_name)\n",
    "for model_evaluation in list_evaluation_pager:\n",
    "  metrics_dict = {m[0]: m[1] for m in model_evaluation.metrics.items()}\n",
    "  df = pd.DataFrame(metrics_dict.items(), columns=[\"Metric\", \"Value\"])\n",
    "  print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIw1ifPuqcTb"
   },
   "source": [
    "# Run Batch Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Output BigQuery Dataset\n",
    "First, create a new BigQuery dataset for the batch prediction output in the same region as the batch prediction input dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nT-bZ1autijD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "\n",
    "batch_predict_bq_input_uri = \"bq://bigquery-public-data.iowa_liquor_sales_forecasting.2021_sales_predict\"\n",
    "batch_predict_bq_output_dataset_name = \"iowa_liquor_sales_predictions\"\n",
    "batch_predict_bq_output_dataset_path = \"{}.{}\".format(PROJECT_ID, batch_predict_bq_output_dataset_name)\n",
    "batch_predict_bq_output_uri_prefix = \"bq://{}.{}\".format(PROJECT_ID, batch_predict_bq_output_dataset_name)\n",
    "# Must be the same region as batch_predict_bq_input_uri\n",
    "client = bigquery.Client()\n",
    "dataset = bigquery.Dataset(batch_predict_bq_output_dataset_path)\n",
    "dataset_region = \"US\" # @param {type : \"string\"}\n",
    "dataset.location = dataset_region\n",
    "dataset = client.create_dataset(dataset)\n",
    "print(\"Created bigquery dataset {} in {}\".format(batch_predict_bq_output_dataset_path, dataset_region))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krKRn9W0xxI2"
   },
   "source": [
    "Run a batch prediction job to generate liquor sales forecasts for stores in Iowa from an input dataset containing historical sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8I8aRjRh6GGG"
   },
   "outputs": [],
   "source": [
    "model.batch_predict(\n",
    "   bigquery_source=batch_predict_bq_input_uri,\n",
    "   instances_format=\"bigquery\",\n",
    "   bigquery_destination_prefix=batch_predict_bq_output_uri_prefix,\n",
    "   predictions_format=\"bigquery\",\n",
    "   job_display_name=\"predict-iowa-liquor-sales-automl_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Forecasts\n",
    "Follow the this link to visualize the generated forecasts in [Data Studio](https://support.google.com/datastudio/answer/6283323?hl=en)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "CTQl3fH6Ur2Z"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "tables = client.list_tables(batch_predict_bq_output_dataset_path)\n",
    "\n",
    "prediction_table_id = \"\"\n",
    "for table in tables:\n",
    "  if table.table_id.startswith(\n",
    "      \"predictions_\") and table.table_id > prediction_table_id:\n",
    "    prediction_table_id = table.table_id\n",
    "batch_predict_bq_output_uri = \"{}.{}\".format(\n",
    "    batch_predict_bq_output_dataset_path, prediction_table_id)\n",
    "\n",
    "\n",
    "def _sanitize_bq_uri(bq_uri):\n",
    "  if bq_uri.startswith(\"bq://\"):\n",
    "    bq_uri = bq_uri[5:]\n",
    "  return bq_uri.replace(\":\", \".\")\n",
    "\n",
    "\n",
    "def get_data_studio_link(batch_prediction_bq_input_uri,\n",
    "                         batch_prediction_bq_output_uri, time_column,\n",
    "                         time_series_identifier_column, target_column):\n",
    "  batch_prediction_bq_input_uri = _sanitize_bq_uri(\n",
    "      batch_prediction_bq_input_uri)\n",
    "  batch_prediction_bq_output_uri = _sanitize_bq_uri(\n",
    "      batch_prediction_bq_output_uri)\n",
    "  base_url = \"https://datastudio.google.com/c/u/0/reporting\"\n",
    "  query = \"SELECT \\\\n\" \\\n",
    "  \" CAST(input.{} as DATETIME) timestamp_col,\\\\n\" \\\n",
    "  \" CAST(input.{} as STRING) time_series_identifier_col,\\\\n\" \\\n",
    "  \" CAST(input.{} as NUMERIC) historical_values,\\\\n\" \\\n",
    "  \" CAST(predicted_{}.value as NUMERIC) predicted_values,\\\\n\" \\\n",
    "  \" * \\\\n\" \\\n",
    "  \"FROM `{}` input\\\\n\" \\\n",
    "  \"LEFT JOIN `{}` output\\\\n\" \\\n",
    "  \"ON\\\\n\" \\\n",
    "  \"CAST(input.{} as DATETIME) = CAST(output.{} as DATETIME)\\\\n\" \\\n",
    "  \"AND CAST(input.{} as STRING) = CAST(output.{} as STRING)\"\n",
    "  query = query.format(time_column, time_series_identifier_column,\n",
    "                       target_column, target_column,\n",
    "                       batch_prediction_bq_input_uri,\n",
    "                       batch_prediction_bq_output_uri, time_column, time_column,\n",
    "                       time_series_identifier_column,\n",
    "                       time_series_identifier_column)\n",
    "  params = {\n",
    "      \"templateId\": \"067f70d2-8cd6-4a4c-a099-292acd1053e8\",\n",
    "      \"ds0.connector\": \"BIG_QUERY\",\n",
    "      \"ds0.projectId\": PROJECT_ID,\n",
    "      \"ds0.billingProjectId\": PROJECT_ID,\n",
    "      \"ds0.type\": \"CUSTOM_QUERY\",\n",
    "      \"ds0.sql\": query\n",
    "  }\n",
    "  params_str_parts = []\n",
    "  for k, v in params.items():\n",
    "    params_str_parts.append(\"\\\"{}\\\":\\\"{}\\\"\".format(k, v))\n",
    "  params_str = \"\".join([\"{\", \",\".join(params_str_parts), \"}\"])\n",
    "  return \"{}?{}\".format(base_url,\n",
    "                        urllib.parse.urlencode({\"params\": params_str}))\n",
    "\n",
    "\n",
    "print(\n",
    "    get_data_studio_link(batch_predict_bq_input_uri,\n",
    "                         batch_predict_bq_output_uri, time_column,\n",
    "                         time_series_identifier_column, target_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24NPJ7nCRchZ"
   },
   "source": [
    "# Cleaning up\n",
    "\n",
    "The lab resources will automatically be cleaned up by Qwiklabs but if you are reusing this notebook in your own environment you can use this cell to remove the Vertex AI model and Cloud Storage Bucket created for this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gq3ZSsAkRnXh"
   },
   "outputs": [],
   "source": [
    "# Delete model resource\n",
    "model.delete(sync=True)\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "! gsutil -m rm -r $BUCKET_NAME"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Vertex AI SDK - Vertex AI Forecasting Model Training Example",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
