{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VQkf8sFTeDo",
    "tags": []
   },
   "source": [
    "# Getting Started with Text Embeddings + Vertex AI Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, you learn how to use Google Cloud AI tools to quickly bring the power of Large Language Models to enterprise systems.  \n",
    "\n",
    "This tutorial covers the following -\n",
    "\n",
    "*   What are embeddings - what business challenges do they help solve ?\n",
    "*   Understanding Text with Vertex AI Text Embeddings\n",
    "*   Find Embeddings fast with Vertex AI Vector Search\n",
    "*   Grounding LLM outputs with Vector Search\n",
    "\n",
    "This tutorial is based on [the blog post](https://cloud.google.com/blog/products/ai-machine-learning/how-to-use-grounding-for-your-llms-with-text-embeddings), combined with sample code.\n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This tutorial is designed for developers who has basic knowledge and experience with Python programming and machine learning.\n",
    "\n",
    "If you are not reading this tutorial in Qwiklab, then you need to have a Google Cloud project that is linked to a billing account to run this. Please go through [this document](https://cloud.google.com/vertex-ai/docs/start/cloud-environment) to create a project and setup a billing account for it.\n",
    "\n",
    "### Choose the runtime environment\n",
    "\n",
    "The notebook can be run on either Google Colab or [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench).\n",
    "\n",
    "- To use Colab: Click [this link](https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/embeddings/intro-textemb-vectorsearch.ipynb) to open the tutorial in Colab.\n",
    "\n",
    "- To use Workbench: If it is the first time to use Workbench in your Google Cloud project, open [the Workbench console](https://console.cloud.google.com/vertex-ai/workbench) and click ENABLE button to enable Notebooks API. Then click [this link](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/embeddings/intro-textemb-vectorsearch.ipynb),  and select an existing notebook or create a new notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pImjuenUIQz"
   },
   "source": [
    "### How much will this cost?\n",
    "\n",
    "In case you are using your own Cloud project, not a temporary project on Qwiklab, you need to spend roughly a few US dollars to finish this tutorial.\n",
    "\n",
    "The pricing of the Cloud services we will use in this tutorial are available in the following pages:\n",
    "\n",
    "- [Vertex AI Embeddings for Text](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)\n",
    "- [Vertex AI Vector Search](https://cloud.google.com/vertex-ai/pricing#matchingengine)\n",
    "- [BigQuery](https://cloud.google.com/bigquery/pricing)\n",
    "- [Cloud Storage](https://cloud.google.com/storage/pricing)\n",
    "- [Vertex AI Workbench](https://cloud.google.com/vertex-ai/pricing#notebooks) if you use one\n",
    "\n",
    "You can use the [Pricing Calculator](https://cloud.google.com/products/calculator) to generate a cost estimate based on your projected usage. The following is an example of rough cost estimation with the calculator, assuming you will go through this tutorial a couple of time.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/github-repo/img/embeddings/vs-quickstart/pricing.png\" width=\"50%\"/>\n",
    "\n",
    "### **Warning: delete your objects after the tutorial**\n",
    "\n",
    "In case you are using your own Cloud project, please make sure to delete all the Indexes, Index Endpoints and Cloud Storage buckets (and the Workbench instance if you use one) after finishing this tutorial. Otherwise the remaining assets would incur unexpected costs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Fu2OoUDTQ6w"
   },
   "source": [
    "# Bringing Gen AI and LLMs to production services\n",
    "\n",
    "Many people are now starting to think about how to bring Gen AI and LLMs to production services, and facing with several challenges.\n",
    "\n",
    "- \"How to integrate LLMs or AI chatbots with existing IT systems, databases and business data?\"\n",
    "- \"We have thousands of products. How can I let LLM memorize them all precisely?\"\n",
    "- \"How to handle the hallucination issues in AI chatbots to build a reliable service?\"\n",
    "\n",
    "Here is a quick solution: **grounding** with **embeddings** and **vector search**.\n",
    "\n",
    "What is grounding? What are embedding and vector search? In this tutorial, we will learn these crucial concepts to build reliable Gen AI services for enterprise use. But before we dive deeper, let's try the demo below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORqZYLgTm9pJ"
   },
   "source": [
    "![](https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1._demo_animation.gif)\n",
    "\n",
    "**Exercise: Try the Stack Overflow semantic search demo:**\n",
    "\n",
    "This demo is available as a [public live demo](https://ai-demos.dev/). Select \"STACKOVERFLOW\" and enter any coding question as a query, so it runs a text search on **8 million** questions posted on [Stack Overflow](https://stackoverflow.com/). Try the text semantic search with some queries like 'How to shuffle rows in SQL?' or arbitrary programming questions.\n",
    "\n",
    "In this tutorial, we are going to see how to build a similar search experience - what is involved in building solutions like this using Vertex AI Embeddings API and Vector Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1MAIOkCw35V"
   },
   "source": [
    "# What is Embeddings?\n",
    "\n",
    "With the rise of LLMs, why is it becoming important for IT engineers and ITDMs to understand how they work?\n",
    "\n",
    "In traditional IT systems, most data is organized as structured or tabular data, using simple keywords, labels, and categories in databases and search engines.\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/textemb-vs-notebook/1.png)\n",
    "\n",
    "In contrast, AI-powered services arrange data into a simple data structure known as \"embeddings.\"\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/textemb-vs-notebook/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJqjBmQsxz2Z"
   },
   "source": [
    "Once trained with specific content like text, images, or any content, AI creates a space called \"embedding space\", which is essentially a map of the content's meaning.\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/textemb-vs-notebook/3.png)\n",
    "\n",
    "AI can identify the location of each content on the map, that's what embedding is.\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/textemb-vs-notebook/4.png)\n",
    "\n",
    "Let's take an example where a text discusses movies, music, and actors, with a distribution of 10%, 2%, and 30%, respectively. In this case, the AI can create an embedding with three values: 0.1, 0.02, and 0.3, in 3 dimensional space.\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/textemb-vs-notebook/5.png)\n",
    "\n",
    "AI can put content with similar meanings closely together in the space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5z7vyTyzk_4"
   },
   "source": [
    "This is how Google organizes data across various services like Google Search, YouTube, Play, and many others, to provide search results and recommendations with relevant content.\n",
    "\n",
    "Embeddings can also be used to represent different types of things in businesses, such as products, users, user activities, conversations, music & videos, signals from IoT sensors, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpKVmyEe0ab9"
   },
   "source": [
    "AI and Embeddings are now playing a crucial role in creating a new way of human-computer interaction.\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/textemb-vs-notebook/6.png)\n",
    "\n",
    "AI organizes data into embeddings, which represent what the user is looking for, the meaning of contents, or many other things you have in your business. This creates a new level of user experience that is becoming the new standard.\n",
    "\n",
    "To learn more about embeddings, [Foundational courses: Embeddings on Google Machine Learning Crush Course](https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture) and [Meet AI’s multitool: Vector embeddings by Dale Markowitz](https://cloud.google.com/blog/topics/developers-practitioners/meet-ais-multitool-vector-embeddings) are great materials.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovQpiL2GUEXa"
   },
   "source": [
    "# Vertex AI Embeddings for Text\n",
    "\n",
    "With the [Vertex AI Embeddings for Text](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings), you can easily create a text embedding with LLM. The product is also available on [Vertex AI Model Garden](https://cloud.google.com/model-garden)\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/textemb-vs-notebook/7.png)\n",
    "\n",
    "This API is designed to extract embeddings from texts. It can take text input up to 3,072 input tokens, and outputs 768 dimensional text embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwJHDPG7lU52"
   },
   "source": [
    "## LLM text embedding business use cases\n",
    "\n",
    "With the embedding API, you can apply the innovation of embeddings, combined with the LLM capability, to various text processing tasks, such as:\n",
    "\n",
    "**LLM-enabled Semantic Search**: text embeddings can be used to represent both the meaning and intent of a user's query and documents in the embedding space. Documents that have similar meaning to the user's query intent will be found fast with vector search technology. The model is capable of generating text embeddings that capture the subtle nuances of each sentence and paragraphs in the document.\n",
    "\n",
    "**LLM-enabled Text Classification**: LLM text embeddings can be used for text classification with a deep understanding of different contexts without any training or fine-tuning (so-called zero-shot learning). This wasn't possible with the past language models without task-specific training.\n",
    "\n",
    "**LLM-enabled Recommendation**: The text embedding can be used for recommendation systems as a strong feature for training recommendation models such as Two-Tower model. The model learns the relationship between the query and candidate embeddings, resulting in next-gen user experience with semantic product recommendation.\n",
    "\n",
    "LLM-enabled Clustering, Anomaly Detection, Sentiment Analysis, and more, can be also handled with the LLM-level deep semantics understanding.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga5A7koYlvlZ"
   },
   "source": [
    "## Sorting 8 million texts at \"librarian-level\" precision\n",
    "\n",
    "Vertex AI Embeddings for Text has an embedding space with 768 dimensions. As explained earlier, the space represents a huge map of a wide variety of texts in the world, organized by their meanings. With each input text, the model can find a location (embedding) in the map.\n",
    "\n",
    "By visualizing the embedding space, you can actually observe how the model sorts the texts at the \"librarian-level\" precision.\n",
    "\n",
    "**Exercise: Try the Nomic AI Atlas**\n",
    "\n",
    "[Nomic AI](http://nomic.ai/) provides a platform called Atlas for storing, visualizing and interacting with embedding spaces with high scalability and in a smooth UI, and they worked with Google for visualizing the embedding space of the 8 million Stack Overflow questions. You can try exploring around the space, zooming in and out to each data point on your browser on this page, courtesy of Nomic AI.\n",
    "\n",
    "The embedding space represents a huge map of texts, organized by their meanings\n",
    "With each input text, the model can find a location (embedding) in the map\n",
    "Like a librarian reading through millions of texts, sorting them with millions of nano-categories\n",
    "\n",
    "Try exploring it [here](https://atlas.nomic.ai/map/edaff028-12b5-42a0-8e8b-6430c9b8222b/bcb42818-3581-4fb5-ac30-9883d01f98ec). Zoom into a few categories, point each dots, and see how the LLM is sorting similar questions close together in the space.\n",
    "\n",
    "![](https://storage.googleapis.com/gweb-cloudblog-publish/images/4._Nomic_AI_Atlas.max-2200x2200.png)\n",
    "\n",
    "### The librarian-level semantic understanding\n",
    "\n",
    "Here are the examples of the librarian-level semantic understanding by Embeddings API with Stack Overflow questions.\n",
    "\n",
    "![](https://storage.googleapis.com/gweb-cloudblog-publish/images/5._semantic_understanding.max-2200x2200.png)\n",
    "\n",
    "For example, the model thinks the question “Does moving the request line to a header frame require an app change?” is similar to the question “Does an application developed on HTTP1x require modifications to run on HTTP2?”. That is because The model knows both questions talk about what's the change required to support the HTTP2 header frame.\n",
    "\n",
    "Note that this demo didn't require any training or fine-tuning with computer programming specific datasets. This is the innovative part of the zero-shot learning capability of the LLM. It can be applied to a wide variety of industries, including finance, healthcare, retail, manufacturing, construction, media, and more, for deep semantic search on the industry-focused business documents without spending time and cost for collecting industry specific datasets and training models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iOWOKnIvYxf"
   },
   "source": [
    "# Text Embeddings in Action\n",
    "\n",
    "Lets try using Text Embeddings in action with actual sample code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtXnXhF8U-8R"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Before get started with the Vertex AI services, we need to setup the following.\n",
    "\n",
    "* Install Python SDK\n",
    "* Environment variables\n",
    "* Authentication (Colab only)\n",
    "* Enable APIs\n",
    "* Set IAM permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjnvWl6FLUlF"
   },
   "source": [
    "### Install Python SDK\n",
    "\n",
    "Vertex AI, Cloud Storage and BigQuery APIs can be accessed with multiple ways including REST API and Python SDK. In this tutorial we will use the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FZgLGALt_al7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.57.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.58.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: google-cloud-bigquery[pandas] in /opt/conda/lib/python3.10/site-packages (3.25.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.30.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.7.4)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (2.9.0)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (2.2.2)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (16.1.0)\n",
      "Requirement already satisfied: db-dtypes<2.0.0dev,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from db-dtypes<2.0.0dev,>=0.3.0->google-cloud-bigquery[pandas]) (1.26.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.0->google-cloud-bigquery[pandas]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.0->google-cloud-bigquery[pandas]) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery[pandas]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.6.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Downloading google_cloud_aiplatform-1.58.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-api-core, google-cloud-storage, google-cloud-aiplatform\n",
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.19.1 google-cloud-aiplatform-1.58.0 google-cloud-storage-2.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --user google-cloud-aiplatform google-cloud-storage 'google-cloud-bigquery[pandas]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart current runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRvKdaPDTznN",
    "outputId": "154a71b5-f302-4f53-ed2f-b3e5fef9195b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCoTvkOJoh76"
   },
   "source": [
    "### Environment variables\n",
    "\n",
    "Sets environment variables. If asked, please replace the following `[your-project-id]` with your project ID and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fkmvFRrj3nQI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get project ID\n",
    "PROJECT_ID = ! gcloud config get project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\"\n",
    "if PROJECT_ID == \"(unset)\":\n",
    "    print(f\"Please set the project ID manually below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "69XJ95rNoYG9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define project information\n",
    "if PROJECT_ID == \"(unset)\":\n",
    "    PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# generate an unique id for this session\n",
    "from datetime import datetime\n",
    "\n",
    "UID = datetime.now().strftime(\"%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ph7mDSMRVTIZ"
   },
   "source": [
    "### Authentication (Colab only)\n",
    "\n",
    "If you are running this notebook on Colab, you will need to run the following cell authentication. This step is not required if you are using Vertex AI Workbench as it is pre-authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5jQkFtlimNXR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# if it's Colab runtime, authenticate the user with Google Cloud\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUPbl4IFLmC2"
   },
   "source": [
    "### Enable APIs\n",
    "\n",
    "Run the following to enable APIs for Compute Engine, Vertex AI, Cloud Storage and BigQuery with this Google Cloud project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qGf0qMMQNond",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation \"operations/acat.p2-148319388360-c20999b9-8b7b-42db-bf19-bb761325b894\" finished successfully.\n"
     ]
    }
   ],
   "source": [
    "! gcloud services enable compute.googleapis.com aiplatform.googleapis.com storage.googleapis.com bigquery.googleapis.com --project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cF8rkN3Lnhq"
   },
   "source": [
    "### Set IAM permissions\n",
    "\n",
    "Also, we need to add access permissions to the default service account for using those services.\n",
    "\n",
    "- Go to [the IAM page](https://console.cloud.google.com/iam-admin/) in the Console\n",
    "- Look for the principal for default compute service account. It should look like: `<project-number>-compute@developer.gserviceaccount.com`\n",
    "- Click the edit button at right and click `ADD ANOTHER ROLE` to add `Vertex AI User`, `BigQuery User` and `Storage Admin` to the account.\n",
    "\n",
    "This will look like this:\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/vs-quickstart/iam-setting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mahCxLXHMIls"
   },
   "source": [
    "## Getting Started with Vertex AI Embeddings for Text\n",
    "\n",
    "Now it's ready to get started with embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rq07_-o0VoZD"
   },
   "source": [
    "### Data Preparation\n",
    "\n",
    "We will be using [the Stack Overflow public dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow) hosted on BigQuery table `bigquery-public-data.stackoverflow.posts_questions`. This is a very big dataset with 23 million rows that doesn't fit into the memory. We are going to limit it to 1000 rows for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "snrzPsEQDH4S",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73237542</td>\n",
       "      <td>How to get random single result from multiple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73398579</td>\n",
       "      <td>How should I increase the test coverage for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73327915</td>\n",
       "      <td>How do you add diagnostic information to iOS c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73515603</td>\n",
       "      <td>[iOS/Safari15.5]border displayed in &lt;video&gt;tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73265831</td>\n",
       "      <td>Compare two strings in GridDB FDW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title\n",
       "0  73237542  How to get random single result from multiple ...\n",
       "1  73398579  How should I increase the test coverage for th...\n",
       "2  73327915  How do you add diagnostic information to iOS c...\n",
       "3  73515603     [iOS/Safari15.5]border displayed in <video>tag\n",
       "4  73265831                  Compare two strings in GridDB FDW"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the BQ Table into a Pandas Dataframe\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "QUESTIONS_SIZE = 1000\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "QUERY_TEMPLATE = \"\"\"\n",
    "        SELECT distinct q.id, q.title\n",
    "        FROM (SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "        where Score > 0 ORDER BY View_Count desc) AS q\n",
    "        LIMIT {limit} ;\n",
    "        \"\"\"\n",
    "query = QUERY_TEMPLATE.format(limit=QUESTIONS_SIZE)\n",
    "query_job = bq_client.query(query)\n",
    "rows = query_job.result()\n",
    "df = rows.to_dataframe()\n",
    "\n",
    "# examine the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6022U1FWzpb"
   },
   "source": [
    "### Call the API to generate embeddings\n",
    "\n",
    "With the Stack Overflow dataset, we will use the `title` column (the question title) and generate embedding for it with Embeddings for Text API. The API is available under the [vertexai](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai) package of the SDK.\n",
    "\n",
    "You may see some warning messages from the TensorFlow library but you can ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pY8M4DqO8wGx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init the vertexai package\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrG82n-y-EC5"
   },
   "source": [
    "From the package, import [TextEmbeddingModel](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models.TextEmbeddingModel) and get a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YVLHjSeOGoTu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the text embeddings model\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqdVsgZDb_hc"
   },
   "source": [
    "In this tutorial we will use `textembedding-gecko@001` model for getting text embeddings. Please take a look at [Supported models](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings#supported_models) on the doc to see the list of supported models.\n",
    "\n",
    "Once you get the model, you can call its [get_embeddings](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models.TextEmbeddingModel#vertexai_language_models_TextEmbeddingModel_get_embeddings) function to get embeddings. You can pass up to 5 texts at once in a call. But there is a caveat. By default, the text embeddings API has a \"request per minute\" quota set to 60 for new Cloud projects and 600 for projects with usage history (see [Quotas and limits](https://cloud.google.com/vertex-ai/docs/quotas#request_quotas) to check the latest quota value for `base_model:textembedding-gecko`). So, rather than using the function directly, you may want to define a wrapper like below to limit under 10 calls per second, and pass 5 texts each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8HUb9u_P2VWW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm  # to show a progress bar\n",
    "\n",
    "# get embeddings for a list of texts\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "\n",
    "def get_embeddings_wrapper(texts):\n",
    "    embs = []\n",
    "    for i in tqdm.tqdm(range(0, len(texts), BATCH_SIZE)):\n",
    "        time.sleep(1)  # to avoid the quota error\n",
    "        result = model.get_embeddings(texts[i : i + BATCH_SIZE])\n",
    "        embs = embs + [e.values for e in result]\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aK4eTSPfcEuh"
   },
   "source": [
    "The following code will get embedding for the question titles and add them as a new column `embedding` to the DataFrame. This will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FcqPvu4PluN1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:40<00:00,  1.10s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73237542</td>\n",
       "      <td>How to get random single result from multiple ...</td>\n",
       "      <td>[-0.026690755039453506, -0.012767455540597439,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73398579</td>\n",
       "      <td>How should I increase the test coverage for th...</td>\n",
       "      <td>[0.004281399771571159, 0.00824031513184309, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73327915</td>\n",
       "      <td>How do you add diagnostic information to iOS c...</td>\n",
       "      <td>[-0.01925487071275711, -0.001175552373751998, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73515603</td>\n",
       "      <td>[iOS/Safari15.5]border displayed in &lt;video&gt;tag</td>\n",
       "      <td>[0.004290241748094559, 0.029158292338252068, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73265831</td>\n",
       "      <td>Compare two strings in GridDB FDW</td>\n",
       "      <td>[-0.012215664610266685, 0.004293608944863081, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  73237542  How to get random single result from multiple ...   \n",
       "1  73398579  How should I increase the test coverage for th...   \n",
       "2  73327915  How do you add diagnostic information to iOS c...   \n",
       "3  73515603     [iOS/Safari15.5]border displayed in <video>tag   \n",
       "4  73265831                  Compare two strings in GridDB FDW   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.026690755039453506, -0.012767455540597439,...  \n",
       "1  [0.004281399771571159, 0.00824031513184309, 0....  \n",
       "2  [-0.01925487071275711, -0.001175552373751998, ...  \n",
       "3  [0.004290241748094559, 0.029158292338252068, 0...  \n",
       "4  [-0.012215664610266685, 0.004293608944863081, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get embeddings for the question titles and add them as \"embedding\" column\n",
    "df = df.assign(embedding=get_embeddings_wrapper(list(df.title)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB53SiJjVN6e"
   },
   "source": [
    "## Look at the embedding similarities\n",
    "\n",
    "Let's see how these embeddings are organized in the embedding space with their meanings by quickly calculating the similarities between them and sorting them.\n",
    "\n",
    "As embeddings are vectors, you can calculate similarity between two embeddings by using one of the popular metrics like the followings:\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/textemb-vs-notebook/8.png)\n",
    "\n",
    "Which metric should we use? Usually it depends on how each model is trained. In case of the model `textembedding-gecko@001`, we need to use inner product (dot product).\n",
    "\n",
    "In the following code, it picks up one question randomly and uses the numpy `np.dot` function to calculate the similarities between the question and other questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lKs6jSu7NiM6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55469833, 0.47174075, 0.44768228, 0.50974731, 0.4865015 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# pick one of them as a key question\n",
    "key = random.randint(0, len(df))\n",
    "\n",
    "# calc dot product between the key and other questions\n",
    "embs = np.array(df.embedding.to_list())\n",
    "similarities = np.dot(embs[key], embs.T)\n",
    "\n",
    "# print similarities for the first 5 questions\n",
    "similarities[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srM04lJBQp4w"
   },
   "source": [
    "Finally, sort the questions with the similarities and print the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lTUVvj9FQlab",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key question: How to make first dropdown not render in reactjs and ant design\n",
      "\n",
      "1.0000 How to make first dropdown not render in reactjs and ant design\n",
      "0.7350 React custom country select hook\n",
      "0.7059 How to make the Material UI menu dropdown at the bottom left of the button\n",
      "0.7029 React Router Dom v6 not working in my React page\n",
      "0.6888 material-ui renderToStaticMarkup not working\n",
      "0.6886 Add a new node between two nodes react-flow-render\n",
      "0.6872 Hydration failed because the initial UI does not match what was rendered on the server. React 18, next link, error in my button component?\n",
      "0.6855 How to change background image in React depending on input value?\n",
      "0.6841 Absolute positioned dropdown causing scrollbar to appear instead of appearing above other divs\n",
      "0.6839 How to get a specific ListItem from Menu Component in MUI for React\n",
      "0.6813 Login page won't render in React v18\n",
      "0.6730 Mat-datepicker (dateChange), (dateInput), (change), (input) are not working if using <mat-datepicker-actions>\n",
      "0.6728 How can I make a multi level dependable dropdown List in Flutter?\n",
      "0.6721 LaunchedEffect doesn't get executed the first time\n",
      "0.6709 How to resolve gatsby-plugin-mdx threw an error while running the onCreateNode lifecycle when passing code to a React Bootstrap Alert?\n",
      "0.6677 Angular - form makes other elements unreadable\n",
      "0.6646 Mui dropdown menu is not close in onMouseLeave\n",
      "0.6616 How can i control Offset in Reactnative Animation?\n",
      "0.6606 How to apply styles to MUI MenuList with styled compoents\n",
      "0.6589 preloader apears on navigation bar only\n"
     ]
    }
   ],
   "source": [
    "# print the question\n",
    "print(f\"Key question: {df.title[key]}\\n\")\n",
    "\n",
    "# sort and print the questions by similarities\n",
    "sorted_questions = sorted(\n",
    "    zip(df.title, similarities), key=lambda x: x[1], reverse=True\n",
    ")[:20]\n",
    "for i, (question, similarity) in enumerate(sorted_questions):\n",
    "    print(f\"{similarity:.4f} {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S75SQzAg1wHV"
   },
   "source": [
    "# Find embeddings fast with Vertex AI Vector Search\n",
    "\n",
    "As we have explained above, you can find similar embeddings by calculating the distance or similarity between the embeddings.\n",
    "\n",
    "But this isn't easy when you have millions or billions of embeddings. For example, if you have 1 million embeddings with 768 dimensions, you need to repeat the distance calculations for 1 million x 768 times. This would take some seconds - too slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sjhTy-a47YH"
   },
   "source": [
    "So the researchers have been studying a technique called [Approximate Nearest Neighbor (ANN)](https://en.wikipedia.org/wiki/Nearest_neighbor_search) for faster search. ANN uses \"vector quantization\" for separating the space into multiple spaces with a tree structure. This is similar to the index in relational databases for improving the query performance, enabling very fast and scalable search with billions of embeddings.\n",
    "\n",
    "With the rise of LLMs, the ANN is getting popular quite rapidly, known as the Vector Search technology.\n",
    "\n",
    "![](https://storage.googleapis.com/gweb-cloudblog-publish/images/7._ANN.1143068821171228.max-2200x2200.png)\n",
    "\n",
    "In 2020, Google Research published a new ANN algorithm called [ScaNN](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html). It is considered one of the best ANN algorithms in the industry, also the most important foundation for search and recommendation in major Google services such as Google Search, YouTube and many others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVOL8BgM2isz"
   },
   "source": [
    "## What is Vertex AI Vector Search?\n",
    "\n",
    "Google Cloud developers can take the full advantage of Google's vector search technology with [Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview) (previously called Matching Engine). With this fully managed service, developers can just add the embeddings to its index and issue a search query with a key embedding for the blazingly fast vector search. In the case of the Stack Overflow demo, Vector Search can find relevant questions from 8 million embeddings in tens of milliseconds.\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/textemb-vs-notebook/9.png)\n",
    "\n",
    "With Vector Search, you don't need to spend much time and money building your own vector search service from scratch or using open source tools if your goal is high scalability, availability and maintainability for production systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBt8tjidSzyU"
   },
   "source": [
    "## Get Started with Vector Search\n",
    "\n",
    "When you already have the embeddings, then getting started with Vector Search is pretty easy. In this section, we will follow the steps below.\n",
    "\n",
    "### Setting up Vector Search\n",
    "- Save the embeddings in JSON files on Cloud Storage\n",
    "- Build an Index\n",
    "- Create an Index Endpoint\n",
    "- Deploy the Index to the endpoint\n",
    "\n",
    "### Use Vector Search\n",
    "\n",
    "- Query with the endpoint\n",
    "\n",
    "### **Tip for Colab users**\n",
    "\n",
    "If you use Colab for this tutorial, you may lose your runtime while you are waiting for the Index building and deployment in the later sections as it takes tens of minutes. In that case, run the following sections again with the new instance to recover the runtime: [Install Python SDK, Environment variables and Authentication](https://colab.research.google.com/drive/1xJhLFEyPqW0qvKiERD6aYgeTHa6_U50N?resourcekey=0-2qUkxckCjt6W03AsqvZHhw#scrollTo=AtXnXhF8U-8R&line=9&uniqifier=1).\n",
    "\n",
    "Then, use the [Utilities](https://colab.research.google.com/drive/1xJhLFEyPqW0qvKiERD6aYgeTHa6_U50N?resourcekey=0-2qUkxckCjt6W03AsqvZHhw#scrollTo=BE1tELsH-u8N&line=1&uniqifier=1) to recover the Index and Index Endpoint and continute with the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pu1a3zjfQ0D"
   },
   "source": [
    "### Save the embeddings in a JSON file\n",
    "To load the embeddings to Vector Search, we need to save them in JSON files with JSONL format. See more information in the docs at [Input data format and structure](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup/format-structure#data-file-formats).\n",
    "\n",
    "First, export the `id` and `embedding` columns from the DataFrame in JSONL format, and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GzZ30d4j_uLU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":73237542,\"embedding\":[-0.026690755,-0.0127674555,0.0565731637,0.0531949513,0.0260093119,-0.030274123,0.0130371191,0.0066545387,0.0215059966,0.0285376608,-0.0045601688,0.0354286805,-0.00221315,-0.0385235958,0.0187470205,0.0181835387,-0.023927778,0.003125689,0.0046291058,0.0258320477,-0.0902404785,-0.0086824736,0.052012939,-0.00137033,-0.0031117261,-0.1199829057,0.0007104428,0.0381164588,-0.0015511807,-0.0186704397,-0.0040906887,0.0166318566,-0.0763438419,-0.0320718288,0.0121375872,0.0077526425,-0.0211003814,0.0786086023,-0.0498223938,0.0248156823,0.0396275744,0.0077115088,0.05457123,-0.0163049828,-0.0688415468,0.0069838837,-0.0427753702,-0.044439286,-0.0386696048,-0.0443202704,-0.0245917961,0.0081024356,-0.0079284627,0.0012396179,-0.0118403155,0.0545323938,-0.0761857629,0.0133910608,-0.0435777567,-0.0260961466,-0.0113077108,0.0208650269,-0.0094119152,0.0004104236,-0.0085626412,0.0506032258,0.0412113219,-0.004124755,-0.0314432643,-0.0008717497,0.018077245,-0.0029302009,-0.0349463969,-0.0136988359,0.0091614872,-0.028692238,-0.019474823,0.017644221,0.04972234,-0.0710225999,-0.0488569364,-0.0139267389,-0.0366515964,-0.0983742774,-0.0895569548,0.0309878457,-0.0154000679,0.0320702642,-0.0101269577,0.0209159143,-0.0353491195,-0.0328783728,0.0055353255,0.0272956453,-0.0111447778,-0.0585305579,-0.0332484096,-0.0210391507,0.0059287902,-0.0309623331,-0.0292779524,-0.0334733427,0.0439480841,-0.0055712271,0.0769563392,-0.0177047234,-0.0630874708,0.042944286,-0.0179826841,-0.1060848385,-0.0064423466,-0.043050494,-0.0386895388,0.0048061735,0.0043300311,0.0147277592,-0.0020544827,-0.0083399611,0.0544035695,0.0042200414,-0.0296831857,-0.002437294,-0.0272185169,-0.0259364508,0.0294789579,0.0284060519,0.013898693,-0.0179829374,0.0141905053,-0.0067641274,0.04246765,-0.02513404,0.0155644007,0.0270796977,0.0540763699,0.005067301,-0.0152842263,0.0526180938,0.0520499833,0.0393997245,-0.0258526672,0.0376185812,-0.0148389172,0.0335977376,0.0200308375,-0.0401091091,-0.0280150976,0.0474793464,-0.0306135211,-0.0622503199,-0.003903921,-0.0450284444,-0.0167405903,0.0477381237,0.0503536463,0.0165485386,0.0747104734,0.0257365853,0.0436104462,-0.0759468451,-0.0027857204,-0.0721016526,0.0478828661,-0.0128878504,0.0301872864,0.038786076,-0.003465195,-0.0017091612,-0.0126572,-0.0046321116,0.0360605605,-0.1295193434,0.0376785174,-0.0684042871,0.0468445718,-0.0301409159,-0.0212318432,0.0274676606,0.0307162777,-0.0320907682,0.0013223831,-0.0113261407,0.0302379243,0.0085981181,-0.0811951533,0.0031776826,-0.0481660664,-0.0400908366,-0.0322220996,-0.0033416362,-0.0321847796,0.0087105939,0.0084283054,-0.0509627275,-0.0607207827,0.0216949414,0.0833377168,-0.105810225,-0.0661499426,0.0002144941,-0.0089230081,0.0135783413,0.0467635207,0.0350718312,-0.0368054546,-0.0042105024,-0.0175146237,0.0261715092,-0.022643337,0.0222522765,-0.0247825366,-0.0214521401,0.1019725874,0.0159072671,-0.0117068496,0.050594043,0.0539706722,-0.0797150284,-0.0402476266,0.036816936,-0.0300532207,0.0105706062,0.0470761061,-0.0234653093,-0.0070100068,0.0106999483,0.0070654051,0.0152702713,0.0319152698,0.0020955764,-0.0443890914,-0.0062599839,-0.0187638626,-0.0357172489,0.035274256,0.0646509752,0.0309313703,0.0123367254,-0.0570548773,0.0612747595,0.0017076359,0.0453925021,-0.0003343414,-0.0163712204,-0.0298473239,0.018221071,-0.0143109402,0.0380474813,0.0365541242,-0.0010100077,0.0128322151,-0.0896275863,-0.0174552165,0.0030715566,-0.0067980289,0.014062955,0.023493873,0.0644756332,0.0127478708,0.0196478441,0.0148066645,0.0194434468,0.0119739668,0.1046264246,-0.0328143351,-0.0107427947,-0.0328767896,-0.0276442468,0.0821113363,-0.0345758274,0.0092965588,0.0023564419,-0.0087393979,0.0407068245,0.0035620416,0.0489274189,-0.0056325202,0.034676943,0.037812233,0.0544120148,0.0321727805,0.0283700451,0.0137455435,0.0167445485,-0.0542918518,0.0504810847,-0.004819748,-0.0180169158,-0.0676443055,-0.011343509,0.0204092246,-0.0021810187,0.0078017777,0.0673436522,0.0189302452,-0.0382494777,0.0834623128,0.0125589417,-0.0295674857,0.0216868818,-0.0197964087,-0.0294007044,0.0263145305,-0.001933263,-0.0104160206,-0.0041204677,0.0458225235,-0.0198487453,0.0730921626,0.0061474056,0.005736866,-0.0213989597,-0.0086332038,0.0630565435,-0.0153574971,-0.0040306021,0.0025287992,-0.0352604799,-0.0335870087,0.0732315034,-0.0454699211,0.0086606639,-0.0091180345,-0.0177639592,0.0122274067,-0.0018579627,0.0056375475,0.0013722897,0.101291813,-0.0275808517,-0.0103749372,0.0138791669,0.0055692475,0.0251109898,-0.0319604799,-0.0398906805,0.0230519306,0.0539817959,0.0034438935,-0.0785506293,0.0619752631,-0.0100523643,-0.064815104,-0.0037711756,-0.0034296217,-0.0169699546,-0.0439375266,-0.0138605656,-0.0135511095,-0.0461976007,0.012625318,0.0613641553,-0.0124736922,0.0236431938,-0.0017307429,-0.0070602298,0.0031788077,0.010536938,0.0343498513,-0.0371912718,-0.0296113361,-0.0235183816,-0.0350736305,-0.0264597367,-0.0221624002,0.0158371329,-0.0115285907,0.0458506979,0.040807195,-0.0056744767,-0.0448052287,-0.0157850608,-0.0351229869,-0.0232480541,-0.0686200932,0.0175667834,-0.059175536,0.016517587,0.0068767695,0.0395362899,0.0228353627,-0.0169445332,0.0152488351,0.0048156381,-0.0373767726,0.005995539,0.0666715801,0.0361197963,-0.0241726581,-0.0597965829,-0.0347843841,0.0473110043,0.0180735346,-0.0215377603,-0.0030711461,0.0252788085,-0.0032607096,0.0094973678,-0.0147138117,-0.0398582518,0.044612214,0.0347055942,-0.0638774931,-0.1159822345,0.0403014868,0.0528722517,0.062919192,-0.0219583753,0.0271802954,-0.0242349077,0.0153524848,0.003446802,0.0336726494,0.0283683743,-0.0065263254,-0.0044192821,-0.0284010563,-0.0342269801,-0.0336928479,-0.0039422931,0.0553486906,-0.0165045466,-0.0910122469,0.030002052,-0.0012087676,-0.0591122024,-0.028175503,0.0220577568,-0.0202906728,-0.0542679094,-0.0259903278,0.0456758104,0.0253316648,-0.0576329455,-0.0223863758,-0.0741042718,0.0950254202,0.0780895576,0.0180207565,-0.0128397373,0.0238271821,-0.0140500981,-0.0363735706,0.0060076686,0.0396116488,-0.0406878516,0.006308266,-0.0309635587,-0.0783368424,-0.0535901152,-0.0591395944,-0.031162817,-0.0171161182,0.0628309995,0.0009517056,0.0005837239,0.0462183431,-0.0116432179,-0.0107975435,-0.0034018969,-0.0212974865,0.0224412065,-0.0789401084,0.0103390692,0.0302746389,0.0022726113,0.0080688735,0.0060175299,-0.0262987539,0.0029543762,-0.0498531051,0.0327981338,-0.0124591189,-0.020702444,0.0433098413,-0.0141320499,0.061453063,0.0338881873,-0.034897197,-0.0005675631,-0.0238275696,-0.0351346694,0.0002260592,0.0690572783,0.0015176919,-0.0274164118,-0.0120651824,-0.019843692,0.0229439866,0.0050827875,0.0195209533,-0.0267020166,0.0270884056,0.0314097106,0.0441675894,-0.0056353272,-0.0060070655,-0.0049225744,0.0129246162,-0.0132765239,-0.0148963351,0.0293702129,0.0168088097,-0.0055820555,0.0127007794,-0.0325067006,-0.0092733083,-0.0113359075,-0.034617167,0.01137101,0.0166134108,0.019227799,-0.0142701501,-0.0641577244,-0.0252244044,-0.0834032372,-0.0389802344,0.0209913086,-0.0144603783,-0.0315086953,0.0253542066,-0.0171180889,-0.016566433,0.0154355643,-0.0088863457,0.0283005722,0.054384008,-0.029556511,-0.0259094387,0.0022753926,0.0554207824,0.0505797043,0.035618525,0.0618160255,0.0003907652,-0.017656317,-0.0233583953,-0.0099703027,0.0642544106,0.0909195989,-0.0136056188,-0.0423416942,0.0160134193,0.0059765996,0.0031375696,-0.0361266732,0.0030662143,-0.0118784159,-0.0542396978,0.0183026008,0.0022870414,0.0082969023,-0.0120063908,0.0495511964,-0.0241260286,-0.0425310433,-0.0106781805,-0.0440057069,-0.0260442253,-0.0704101101,-0.0333222263,0.0608747192,0.0082038855,-0.0185182076,0.0159649439,-0.0016464981,0.0288643558,0.0112842284,0.0084930854,0.0262641665,-0.0291425791,-0.0236750245,-0.036357414,-0.0069280197,-0.0175610036,-0.0067308755,-0.0171317067,-0.0573518611,0.0160678104,0.0308799855,0.0066393008,0.0263475124,0.0047740247,0.0558575056,-0.0778893009,0.0258555468,-0.0429231673,-0.0145520652,-0.0122461114,-0.0243330803,0.0319471173,-0.0427813567,-0.0171238352,-0.0065321638,-0.0699119642,-0.0358593427,-0.0739442706,-0.005502345,0.0064911754,0.0165010281,-0.0168705937,0.0013360241,0.0540187471,-0.0144410105,0.0338862464,-0.0088333953,-0.0027806608,0.0381703191,-0.0056500691,0.0578060038,0.0079932194,0.0392889194,0.0008825046,0.0062227282,-0.0480554029,0.0010242059,-0.0524484813,-0.0098192403,0.0139995348,0.0325768106,0.0342271775,0.0163383652,-0.0070016058,-0.0705270395,-0.0022019017,0.0290328208,0.0142220799,0.0170560982,-0.0349448994,-0.0359810106,0.0122356834,-0.0361636728,-0.0543402359,-0.0245388392,0.0173348766,-0.0248729065,0.0168195274,0.0303920433,0.0429812893,0.0315395631,-0.0426538922,-0.020153353,-0.0111168111,-0.0327319466,-0.02681024,-0.002536708,0.031311322,-0.0147529133,-0.0113449441,-0.0014894363,0.0551522337,-0.0133021018,-0.0314851962,-0.0527370907,0.038862966,0.0380499288,0.0110222436,0.0091133239,-0.0320785567,0.0301970132,0.032327611,0.0220242646,0.0815489963,-0.0108295754,-0.0697665066,0.0832644925,-0.0204130821,-0.0203370471,0.023133738,0.0380353034,-0.021724632,-0.000110363,0.0365639329,-0.02480831,0.0091271028,0.030900171,0.0561871231,0.0117326779,0.0385610163,0.0466297939,-0.0239066835,0.0091378074,0.020046059,-0.0290303454,0.0441396162,-0.0209711809,-0.0032937038,0.0119050723,0.0068399291,0.0170361642,-0.0009240262,0.025344504,-0.0660730675,0.0157482475,0.0576099716,-0.0895939022,-0.0160963014,-0.0241921823,-0.036204353,0.0285097137,-0.0139975101,0.0234194435,0.0230271183,0.0492674522,0.0356103256,-0.0131983319,0.0075805569,-0.0050948444,-0.0131736882,0.0040990859,0.0381116681,-0.0394191891,0.0176969022,0.0371694937,0.0060457927,0.0276228711,-0.1000215709,0.0395007245,0.0293811075,0.0078167217,-0.0179093536,0.0122799212,0.0286381133,-0.0221706703,0.0016793923,-0.0071640126,0.0294964202,-0.0064778426,0.0221288819,-0.0346044563,-0.0049183969,-0.0207255706,0.0101659056,0.020125933,0.0297328364,0.0041475142,0.0733117759,0.0054479833,-0.0040509473,-0.0497672819,0.013072188,-0.0183514282,0.0008556123,0.0140830707,0.0440531969,0.0191083811,-0.006898284,0.0065827761,-0.0035571824,-0.0413264595,-0.0571609251,0.0040910826,0.0093476875,0.027653683,0.0280486252,0.0336696431,-0.0088980626,0.0567011088,0.0428075008,0.0307840556,0.0196406804,-0.0059188935,-0.0314650647,0.0312603787,0.0265680235,0.0079906769,-0.0898270831,-0.0387208983]}\n",
      "{\"id\":73398579,\"embedding\":[0.0042813998,0.0082403151,0.0026512232,0.0303951893,0.0233625472,-0.0631263629,-0.015753502,-0.0084796362,-0.0429038666,-0.0129778935,0.003893082,0.0030180542,-0.0068655,0.0163739044,0.0053268159,-0.0413173251,-0.0565726273,-0.0250858217,0.0110074729,0.0000405791,-0.0199756697,0.024657296,0.0242789425,-0.032633841,0.0216691922,-0.0873730332,0.0600695275,-0.0274005141,0.0081272963,0.0001760043,0.0263086781,-0.0184153654,-0.0400626995,-0.0481744185,-0.0365148522,0.0023909127,-0.0112725142,0.0636388734,0.0110114366,0.0112745762,0.0075638467,-0.0134512763,-0.0029284952,-0.0120790061,-0.0273561869,-0.007256235,-0.0001419733,-0.0077669611,0.0068167662,-0.0207624454,-0.0353590846,-0.0241356362,-0.0246274546,0.0332381204,-0.0070754555,0.0490291454,-0.0296880472,0.0205891076,-0.0124600111,-0.007860329,0.0000918788,-0.0254977718,-0.0453762077,-0.0058133951,0.0009645793,0.0326461419,0.0490670539,0.0048737354,-0.0275615584,0.0151546216,-0.0025273368,-0.0333414674,0.0215950273,-0.0283122752,-0.0160701741,0.0061114216,-0.021211056,-0.0231208336,0.0829706416,-0.0283368435,-0.0599880219,-0.0551381446,-0.0313911773,-0.0500120185,-0.0485790111,0.0668768138,0.0532940291,-0.0286715571,-0.0247421321,0.0278941933,-0.0006733495,0.0010872736,-0.0311358497,0.0000504121,-0.0087630022,-0.0489653796,-0.0137272319,-0.0215348825,0.0454185493,0.0034444304,-0.0253030658,-0.0487245582,0.0336082093,-0.0171180218,0.0734854937,-0.0014352669,-0.0295587406,0.0245863609,-0.0150232604,-0.0508648977,-0.0172366817,0.0045012501,-0.0665379018,0.0319356956,0.0229082424,-0.0113154119,-0.0065492084,-0.0217422191,0.0612634942,-0.0014616724,-0.0446604751,0.0196716897,-0.0044296347,0.0566068664,0.0171986297,-0.0077786455,0.0611793362,-0.0030371549,0.0357995555,-0.0069697867,-0.001887907,0.0487896577,0.0202547796,-0.0164715387,-0.0171346702,0.0175489746,-0.0009497954,0.0063135945,0.0783703849,0.0320596956,-0.0493578166,-0.0191194341,-0.0341183357,0.043219965,-0.0162193868,-0.0404150188,0.0259541068,-0.0608964413,-0.0856948867,-0.0428841449,-0.0036998671,0.0302356333,-0.006809128,0.015886141,0.0333096758,0.0384259336,0.0456875935,0.0080175791,0.0195824318,-0.0509481281,-0.0418766961,-0.0180006586,-0.0391877182,0.0379819833,0.0357319564,0.0399582386,0.0050288793,-0.0027820724,-0.0177479349,-0.0447002463,0.0470696241,-0.123431839,0.029450966,-0.0567814223,0.0328174941,0.0438949391,0.0075495699,0.0354956947,0.001494921,0.0252624284,-0.0299788062,-0.1020124853,0.0604825281,-0.0559709072,-0.0105461422,0.0424380638,-0.0148172602,0.0293013528,-0.0434241779,0.0334502347,-0.05496113,-0.024807211,0.0154726226,-0.0485634506,-0.0102595501,-0.0024257121,0.0440700948,-0.1874359101,0.0181607343,0.017353544,-0.0397378542,-0.015779661,-0.0504936129,0.028019432,-0.0065666623,0.0304372832,-0.035906069,0.0000319681,-0.0267091021,0.0345824957,-0.0154873505,0.0004061342,0.0421945676,0.0352548994,0.0196029563,-0.0343224145,0.0134841632,-0.0203518141,-0.0509687141,-0.035907004,-0.0344058648,0.0279305857,-0.0015824055,0.0048697316,0.005749939,0.0033387572,-0.0022618675,-0.0202019885,0.0304170847,-0.0225533005,-0.0068704644,0.0398861319,-0.0376980007,-0.0446464531,-0.0290689301,0.0293576829,0.0296859946,-0.0594759881,-0.0315653794,0.0415528342,0.0369624533,0.0502044708,-0.0391777754,0.0048886868,-0.0056129242,0.0145947943,-0.0282933749,0.0934612155,0.0467808954,0.0011758531,0.0132162916,-0.0661815181,-0.0308792703,0.0255444013,0.0807677656,-0.0223085023,0.0272045061,0.029042501,0.0076758889,0.0211732984,-0.0066969986,0.0056865709,0.0281204674,0.1082699522,0.0161378123,-0.0051764767,0.0188469421,0.0055935886,0.0318349116,-0.0357094109,0.0017519237,-0.0254806969,0.0298821181,0.048313275,-0.028353231,-0.0020116819,0.0027046602,0.0097711803,-0.0015667918,0.0600427724,0.0344313942,-0.0174367987,0.0072579598,0.0376576521,-0.0053609698,0.0350694284,-0.0279240236,0.0173578225,-0.0381570645,-0.0542774498,0.0088792304,0.0287748054,-0.0390917771,0.0326359458,0.0094270213,-0.0295291711,0.0704124421,-0.009794889,-0.0330711082,0.0095591461,-0.0237519853,-0.036704544,0.0267969202,0.0199819151,-0.0537124537,0.0220302884,0.0110242488,-0.0372766107,0.0934998542,0.0137748979,0.0425539538,-0.0124263559,0.0019021068,0.0229922924,-0.0423898213,0.0124201132,0.0567960478,-0.0229274761,-0.0736935362,0.0303579345,-0.0300653707,-0.001431583,0.0081558004,0.0114812106,0.0113172969,-0.0163266566,0.0095941629,-0.0110243428,0.0757303759,-0.0336102284,-0.0432662368,0.0327574424,-0.0566810668,-0.0166729223,-0.0206974801,0.0134511031,-0.0034557858,0.0466600582,-0.0175791197,-0.0493220128,0.0264564063,-0.0187499449,-0.046799235,-0.0419357195,0.021451693,0.0138323614,-0.0206316132,0.0061688772,-0.0211496484,-0.0651622117,-0.0119352322,-0.0349222124,0.0097775962,0.0356447883,0.0524847098,0.0307008177,-0.047937829,0.0009091281,0.0924324542,-0.0245568436,-0.0415821373,0.0136059886,0.0271734744,0.0114856856,0.048941236,-0.0038502812,-0.050197795,0.048261296,0.0549168102,-0.0162851699,-0.0128486296,-0.05211889,-0.0095529286,0.0147187989,-0.0666252524,0.0508583747,-0.0509439595,0.0073358985,-0.0228398535,0.0154889682,-0.0089786956,0.0786550418,0.0262455959,0.0266656559,0.0101413419,0.0226495154,0.038142655,0.0104346247,-0.0324230641,-0.0238164105,0.000516033,0.0341114365,0.0369625129,-0.0052783154,-0.0123577397,0.0902692899,-0.0833749622,0.0326484218,-0.0423376262,-0.011373342,0.0003053358,0.0072718863,-0.0471889451,-0.036401812,0.013193382,0.0551371872,0.041321449,-0.0076636132,-0.0468468107,-0.053247463,0.0632356256,0.004352306,-0.0210506655,0.0499791875,0.0579727031,-0.0429040566,-0.0462104715,-0.0178549588,-0.0324745998,0.0369361378,-0.0091207596,-0.0214701146,-0.064867951,0.047526136,0.0238590185,-0.0253005344,0.0174696781,0.0058537256,-0.0246162247,-0.0354216434,0.007004668,0.0342103653,-0.0550905429,-0.054341305,-0.0462798886,-0.0057057156,0.0664007962,0.0654458031,-0.0123427175,-0.0156019097,0.0411053561,0.0355822928,-0.0342043042,0.0340839848,-0.005206069,-0.0295733232,-0.0808288679,-0.0269680079,0.0019705505,-0.0399177931,-0.061726436,-0.0262963865,0.0251242034,0.0646384582,-0.0018340074,0.0236914307,0.0031977091,-0.011646444,-0.0161899254,-0.0671878308,-0.023360461,-0.0288747586,-0.0470698848,0.0480247587,-0.0408317372,0.0112917256,0.017773021,0.0470587537,0.0046422081,0.0111096725,0.0056913565,0.038238842,-0.0358365998,-0.0108635053,0.0665457845,0.0072867814,0.0547731668,0.0378514715,-0.0037620275,0.0340130813,-0.0303288903,-0.0357492454,-0.0014027632,-0.0058906972,0.0467270501,0.044984404,0.0494890623,-0.0299085435,0.0046724384,0.0520134866,0.0329323187,-0.0240583103,0.0300760157,-0.0341341607,0.0133391069,-0.0200802255,-0.0181990806,-0.0155084124,-0.0092029553,0.0042315386,0.01945889,-0.0643780008,0.026552055,-0.0181882903,-0.0675104633,0.0088304048,-0.0372879356,-0.0190246738,-0.0830112323,0.0100329146,-0.0027419592,0.046276968,0.0133488029,-0.0666916668,-0.0111654541,-0.1371285468,0.0259147417,0.0437230505,0.0026233166,-0.0092862621,0.0081468672,-0.0086068902,0.0100669675,0.0040869312,0.0042294185,0.0016574034,0.0082244994,-0.0494734868,-0.0432482511,-0.0184717476,0.0108870706,0.0054783518,-0.012737656,0.0471358672,-0.0365710035,-0.0543329455,0.0245669167,-0.0408755168,0.0174448937,0.0834278986,-0.0272394344,-0.0188598502,0.0161053631,-0.0020119329,0.0119569376,0.0206089616,-0.0131217111,0.0178901162,-0.0252201259,0.0033066396,0.0225733742,-0.0036508932,-0.0459518209,0.0287646428,0.0417010635,-0.0577648729,0.0229492243,-0.0089617595,-0.0393168703,0.0037632214,-0.020395359,-0.0081345672,-0.0072718202,-0.0267858393,0.0175742228,-0.0048023183,0.0703732595,0.0379528888,-0.007704251,0.0435537472,-0.0297735557,-0.0648417994,-0.0370066576,-0.0248479825,-0.0224283542,0.0633539632,-0.0377963185,-0.0155883906,-0.021398399,0.0258923881,0.0235951245,0.0281958077,-0.0298506375,0.0462127142,-0.0504567362,0.037076883,0.0131130852,0.0135521377,0.0047831531,-0.0201424137,-0.0298914574,-0.0905956402,0.0359439366,-0.021886833,-0.0394350477,-0.0078152725,0.0136762708,0.0274695568,-0.0491910875,0.028747702,-0.0035793986,-0.0057648248,0.0096699074,-0.0251602419,0.0416646749,-0.0038118563,-0.0133424886,0.0055402778,0.0227894206,-0.0017888008,0.0003192805,0.0418395475,0.029538922,-0.039770823,-0.0143544804,-0.0063235438,-0.0179687627,0.001649647,-0.0201028716,-0.0261045471,0.0168476813,0.0300143454,-0.0136909392,-0.0340753421,-0.0397998057,-0.0562885776,-0.0038452095,-0.0029427896,-0.0078627691,-0.0228213482,-0.0124558797,-0.0031961349,-0.0056219618,-0.062338803,0.0104578771,-0.0583746992,0.0119695198,0.0420040339,0.053524442,0.0609122105,0.0525082052,0.0177852716,-0.0164504498,0.0322903544,0.0170514286,0.0025340291,0.0108941533,-0.0088587878,-0.0006174603,-0.0395405516,0.0172678493,-0.0343082398,-0.0255310982,-0.041432932,0.0298422147,0.0098526841,-0.0294734892,0.0305869747,-0.0489419512,-0.0004890302,0.0041454914,-0.0428481437,0.0610098317,0.037258599,-0.0731358454,0.0655795559,0.0190320536,-0.026125038,-0.0172526184,-0.033228755,0.0006923815,-0.0481039956,0.015782645,-0.0089532873,0.0386504345,-0.0226956643,0.0430775099,0.022250602,0.0066826688,-0.0129395276,-0.0418357998,0.0074155522,0.0131810391,-0.0099006249,0.008156864,-0.0505924597,0.0276522581,-0.0463205017,-0.0519983955,-0.0509022549,-0.0073771598,0.0000999637,-0.0735243112,-0.0192541927,0.0302991569,-0.062612012,-0.0422200747,0.0206051506,-0.0178072862,-0.0100093149,-0.0324043445,0.052454818,0.0290953647,0.0753419176,0.0140024107,-0.0705523267,-0.0024011431,-0.0335689038,-0.0200959295,-0.0110063953,0.0327186137,-0.0054433183,0.0888994262,-0.012847269,-0.002852133,0.0524459556,-0.0264251735,-0.0060132882,-0.0116369277,-0.0104861856,-0.0225623623,0.0473678261,0.0164813604,-0.0308774002,-0.0250973552,-0.009967682,-0.0105454437,-0.1177290753,-0.0136138033,0.0054153954,0.0026333786,-0.0145034147,0.0533429794,-0.003072123,0.0171576291,0.0058089457,0.0286360011,0.0097754346,-0.0098688528,-0.0597239323,0.0387200303,0.0895155296,-0.0123443576,0.014966487,0.0149575202,0.0387408137,-0.0500599481,-0.0314581171,-0.0512913354,-0.014943352,-0.0519478619,0.0395889394,-0.0252981763,-0.0156059954,-0.001691405,0.1091383621,0.0251963139,0.0082586464,0.0171984509,0.0575971827,-0.0346224047,-0.0101729566,-0.0395208336,-0.0419826061,0.0464351811,-0.0123440474,-0.0353112929,-0.0259765051]}\n",
      "{\"id\":73327915,\"embedding\":[-0.0192548707,-0.0011755524,-0.0291948486,0.0651577413,0.0335204974,-0.0388681032,-0.0149841225,0.04679133,-0.0027253777,0.0119475992,-0.0176431816,0.0215181354,-0.0095039504,0.0014759836,0.0075778887,-0.0150717208,-0.0172188766,-0.013920729,-0.0163638517,-0.0181757566,-0.0426337272,-0.0214802753,0.0230683386,0.0128741469,0.0117699066,-0.057151977,-0.0141093824,0.0095897028,-0.0309079289,0.0122331865,-0.06241934,0.0200677328,-0.0286013689,-0.0023255155,0.0056093475,-0.0127253961,0.0154025387,0.0060342359,-0.0187787898,0.0239048433,-0.0149343573,-0.0098455762,0.0628202632,0.0114183882,-0.0225939434,0.0234773699,-0.0125004994,0.0415348671,0.0180755015,-0.0182330571,-0.0216886755,-0.0021051858,0.0071121748,-0.0102144536,-0.0025369362,0.0548685342,-0.0429143049,-0.0343723632,-0.0066596447,-0.0211056676,-0.010843657,-0.0180793609,-0.0363124013,-0.0442337282,0.012976774,0.0798647478,0.0785126239,-0.0170935765,-0.046013549,-0.0565106682,-0.013478484,-0.0136893243,0.0335928313,-0.0011117414,0.0356980003,0.0036321536,-0.0095536923,-0.0093118157,0.0480073653,-0.037281692,0.0152809452,-0.0541032739,-0.0060539311,-0.0654344112,-0.0232323036,0.1046121642,-0.0152525157,-0.0049657584,-0.0269504506,0.0421296619,-0.0433013365,0.0022923388,-0.0102269743,0.0057905777,0.004354015,0.0094839586,-0.0319623277,0.0001654442,-0.0120761152,-0.0248614773,0.0380315296,-0.0372117721,0.06792669,-0.0305187292,0.0299190041,-0.0291636307,-0.0458797812,0.0043151332,-0.0802791417,-0.0681436658,-0.066336982,-0.0358587429,-0.0178918149,0.0834206194,0.023845043,-0.0113100139,0.0134768644,-0.0000296881,-0.0157586262,0.0056049088,-0.0307204816,0.0031462312,-0.0069361473,-0.019909298,0.044573456,0.0288971215,0.0903700292,0.0136700794,-0.0203239433,-0.0344935842,0.0362577513,0.0439025201,0.0273439903,-0.0097279446,-0.0064750738,0.050622128,0.0013468604,0.0214130674,0.0043110186,-0.0042477045,-0.0401371419,0.017655516,-0.0219206009,0.0316488743,0.0131733259,-0.0519936681,0.0004024651,-0.0076312646,-0.0442946367,-0.0196983255,0.0318076797,-0.0306653548,-0.0309379753,-0.0174884293,0.0019529848,0.0182244182,0.0125622191,0.027134968,-0.0476229079,-0.0351878218,0.007699925,0.0006408746,0.0344656706,0.0037143955,0.105315879,0.0510465428,0.0576801561,0.0273493603,-0.0037124692,-0.0313711241,-0.0089227976,-0.1266082674,-0.0071911844,-0.0560808629,0.0786796957,-0.006119553,-0.0518766418,0.0501700491,0.0487068407,-0.0152508132,-0.0031484726,-0.0738364831,0.0351443291,-0.0190312937,-0.0798534527,0.0290767699,-0.0021640076,0.0102601433,-0.0207244568,0.0046688961,-0.0131812496,-0.0381768718,-0.0283566676,-0.0639222786,-0.0163758751,-0.003757586,0.0818112493,-0.1128851548,0.005662655,0.0040745866,-0.0066138324,-0.036489889,0.0236749835,0.0425727516,0.012939916,-0.0168658681,-0.0546972416,-0.0005357497,-0.0240287893,0.0085128061,-0.0265202522,0.0313692614,0.060526371,-0.016342178,-0.0081866737,-0.0556346849,0.0209095608,-0.0587778874,-0.0510801859,-0.0162516087,-0.0359225757,0.0288648102,0.021213742,0.0053900545,-0.0379502252,0.0145172393,0.0136556029,0.0134354429,0.0183679275,0.0667423531,-0.0021308183,0.0676073432,-0.0310552139,-0.0117210681,-0.0026739426,0.0157223549,0.0185364131,0.0365823023,-0.1103481054,0.0842203721,0.0523712784,0.0602408201,-0.0040462767,0.0534955598,-0.0297054984,0.0096166767,-0.0232611522,-0.0088825701,-0.0026974892,-0.0198502168,0.054126367,-0.0410208218,-0.0620335378,0.0057146517,0.0131472303,-0.0437948778,0.0005287752,0.0520319864,-0.0115369093,-0.0061743208,0.0455402583,0.0103810979,0.0257372372,0.1208889112,0.0090289405,-0.0300838668,0.0078198742,-0.0371504091,0.0259663388,-0.0432169363,-0.0276199691,-0.0586011074,0.0053824964,0.0005923451,-0.0099857841,0.0094963415,-0.0407028012,0.060461808,0.0212921035,0.0586630777,0.0285194628,-0.0626566336,0.0260232575,0.0222899672,-0.0295944959,0.0326091982,-0.0061778817,0.0282642599,-0.052907832,-0.0102207474,0.0123876752,-0.0213744268,0.0299688987,0.0271376036,-0.0112321917,-0.0318113081,0.0573569201,-0.0262868404,-0.0600712858,0.0115784789,-0.0446448475,0.0254836436,0.0046853949,-0.0112240156,-0.0567122549,-0.0358696766,0.0284247566,-0.0146814976,0.0355878584,0.0118476423,-0.0225434192,-0.0056371894,0.0253733844,-0.0498420335,-0.0613090917,-0.0023616245,0.0649864972,-0.0157187134,-0.0760690644,0.0782219768,-0.0159596447,-0.0201158393,0.0726198554,0.0080471747,-0.0203404706,-0.0307516381,0.0044680205,-0.0289084241,0.025278734,-0.0226571187,-0.0368331857,-0.0154758245,-0.0081028035,-0.0099839661,-0.0424391553,0.0000326417,0.0281297881,0.0173935369,0.0395362005,-0.0250537246,0.0234886371,0.0048944615,-0.0363887586,0.0028927107,0.0234273579,-0.015734138,-0.0247856658,-0.0369970128,0.0186854471,-0.0822861195,0.0174179431,-0.0214794539,0.0045489171,-0.0123814717,0.0352727547,0.004502832,-0.0140288426,-0.0029732261,0.0428388305,-0.0093842186,-0.0537178963,0.0032186063,0.0068883575,-0.0214157868,0.0434618481,0.0273905862,-0.0064464468,0.0080495737,0.0135342702,-0.0265002195,-0.0285459775,-0.0198665392,-0.0112215728,-0.0545791462,-0.0359999165,-0.0202434994,-0.0293325707,0.0165009983,-0.007173276,0.0028631322,0.0276532955,-0.0119916266,-0.0169437937,-0.0158585291,0.0080854241,0.0181164052,0.0547402315,0.0560807623,-0.0285400283,-0.0308483355,0.0448544919,0.0178572237,-0.0244291592,-0.0057829362,-0.0340375155,0.0551798306,-0.0359383784,-0.0352237225,-0.0194427911,-0.0083312504,0.011962533,0.0118866358,-0.0633745417,-0.0787639618,0.0113601275,0.0615918301,-0.0010780701,0.0331292823,-0.0171720069,-0.0632874519,0.0219992697,-0.001472094,-0.0128233368,0.046982348,0.0230286829,-0.0682371631,0.0224757269,-0.0184167661,-0.0029834055,0.0076641687,0.0832212567,-0.0094808536,-0.0403700769,0.0350256264,0.0127215832,0.0334363021,-0.0178805329,-0.0198587906,0.015970733,0.0323838368,0.0123792207,0.0310485214,-0.0087321978,-0.0541726127,-0.0388916694,-0.0421337411,0.0383109711,0.0258208737,0.0392399617,-0.0183878336,-0.0040096682,0.0176049061,-0.032213632,0.0263072532,0.0065716961,-0.0440904908,-0.0240751449,-0.042095352,0.023387624,-0.062722452,0.0079605319,0.007716612,0.039339304,0.0343121998,0.0057579274,0.0071587767,0.0277132858,0.0079777632,-0.0571499579,0.0184595212,-0.0356999375,0.0165250655,-0.0315663517,0.070633471,-0.0093256561,0.0282096751,0.0670084357,-0.0084487163,-0.0232968125,0.0809929967,0.0414300449,0.0498761907,0.0296846479,0.0185289849,-0.0164086092,0.0121165793,0.04645871,0.0938005522,-0.0328383222,-0.0279360078,-0.0573368035,-0.0569464639,-0.0405536555,0.023950696,0.0360069051,0.0301845763,0.0241924394,-0.0062376107,0.0006030552,-0.0199260619,0.0506984256,0.0092744622,0.0385231711,-0.0320855789,0.0210817736,-0.061088901,0.0104867779,0.0569541566,0.0017896208,-0.00038406,0.0391638167,-0.0439999774,0.0094144,0.005781428,-0.0067632818,-0.0183990691,-0.0449105687,-0.0115594361,-0.021004539,0.005236147,-0.015625326,0.0111279944,-0.0136691406,-0.0390924662,-0.0483407192,0.0138760339,-0.0734368116,0.0125945974,0.0104063861,-0.0130579406,-0.0276363473,-0.0135554522,-0.0381578803,0.0375897624,0.0233700443,0.0036942495,0.0097224927,-0.0361291766,-0.0639628395,0.0218014717,0.0233580638,-0.000891328,-0.0159588326,0.0392794386,-0.0570255294,-0.0265980531,0.0664753467,0.003446192,0.0572419539,0.0997923687,0.0173493829,0.0065676952,0.0642190352,0.0331498608,0.0036677967,-0.0078390315,-0.006367682,0.0009982935,0.0151132401,0.098990716,0.0017238361,0.0169638433,-0.0170256943,0.0551151484,0.0493528284,-0.0077397148,0.0734481737,-0.0071234619,-0.0396133065,-0.0205443483,-0.0745143443,0.0043905107,0.0145369358,0.0022229208,0.02917183,-0.0527300239,0.0625911877,0.0018506799,0.0052464865,0.0644468069,-0.0112564089,-0.0675826222,-0.0031086013,-0.003109803,0.0248378366,-0.0285266005,-0.0303681847,0.0451548658,-0.0520041138,0.0049597654,0.0042163851,0.0337206014,0.0320691094,0.0487901531,0.0049489536,-0.0126778018,0.0402126573,-0.006721044,0.0412967056,-0.0666674301,-0.0367617644,-0.0743485019,-0.0103400173,-0.0011117543,-0.0598452576,-0.0145573262,-0.0120648695,-0.0173949171,-0.0134591069,-0.0059182975,0.0022375931,-0.0066945907,-0.070934698,-0.0479029901,-0.0056740139,-0.0124737555,0.0478254445,0.0114974026,0.0755540505,0.0407784767,0.0542359687,0.04543202,-0.0178718511,-0.0115123577,-0.0264070686,0.0209489297,-0.0603263937,0.0221528392,0.0277834535,-0.0072852438,0.0309845861,0.0580191165,-0.0519312769,-0.0648588166,0.0031391194,-0.0190779194,0.0122035276,-0.0156859271,-0.0429607742,0.0107991844,-0.0226481259,-0.029115716,-0.0473706424,-0.0699569732,0.0182893761,-0.032976348,-0.0207875706,0.0632848963,0.0524180941,0.0023247933,0.033136934,0.0477946512,0.0130972443,-0.0708787367,-0.0253589191,-0.0569594763,-0.0225685462,-0.024766244,-0.0025896733,0.0613009259,-0.0147493128,0.005674656,-0.0040809899,-0.0330904201,-0.0290723648,-0.0287947394,0.0187782776,0.0446766093,-0.0112738423,0.0029174518,0.0324677117,-0.0571600869,0.0245183855,0.0431664549,-0.0486998186,0.0787313655,-0.0259517431,-0.0574950799,0.016215995,-0.0272089019,-0.0470534898,-0.0237313826,-0.0075370534,-0.0075282142,-0.0033512863,-0.0006513532,0.0168612897,0.0582394041,0.0252250396,0.0099750198,-0.0288102925,0.0149067743,0.0021965769,0.0137994634,0.0253487583,-0.022156002,0.0337901637,0.0121170608,0.0067810984,0.0126509061,0.0350965671,-0.0462484732,-0.0469292104,0.0272844564,-0.0124686556,-0.085282661,-0.0294397771,-0.0323551446,-0.0257270969,0.0198564567,0.0515665039,0.015850544,0.0636909977,0.0366048217,0.0595542267,-0.0579975024,-0.0036865529,-0.0091236215,-0.0236151572,-0.0185057018,-0.0030009106,0.010376621,0.0460219719,-0.0366949737,-0.0279607978,0.0552952252,-0.0809069648,0.0205680337,-0.0481343232,0.043105226,0.0194045827,0.0455958731,0.0500578843,-0.0277323276,0.0084789209,0.0189002454,-0.014268104,-0.0113692395,-0.0145509606,-0.0426872186,-0.0244318321,-0.0099866912,0.0471128039,0.042014949,0.0575870872,-0.0203183629,0.0472356901,-0.0352827162,0.0108230896,0.000070575,0.0243085474,0.0505503528,0.0280873813,-0.0247985199,-0.0310618915,0.0023814326,0.0020465441,-0.0111575881,-0.0259297881,-0.0022283217,-0.0109636942,0.0412097089,-0.0072400407,0.0371874385,-0.0153648313,0.0465818793,0.0038399308,0.0277643055,0.0009333761,0.0726543441,-0.0547180027,-0.0081918174,-0.0557406768,0.0223014019,0.0147578251,-0.0620568581,-0.0254929494,-0.0729444176]}\n"
     ]
    }
   ],
   "source": [
    "# save id and embedding as a json file\n",
    "jsonl_string = df[[\"id\", \"embedding\"]].to_json(orient=\"records\", lines=True)\n",
    "with open(\"questions.json\", \"w\") as f:\n",
    "    f.write(jsonl_string)\n",
    "\n",
    "# show the first few lines of the json file\n",
    "! head -n 3 questions.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WTNJ3FAQl_W"
   },
   "source": [
    "Then, create a new Cloud Storage bucket and copy the file to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CzwDWJfzAk3n",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-04-befa2ff750b4-embvs-tutorial-07071436/...\n",
      "Copying file://questions.json [Content-Type=application/json]...\n",
      "/ [1 files][  9.8 MiB/  9.8 MiB]                                                \n",
      "Operation completed over 1 objects/9.8 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "BUCKET_URI = f\"gs://{PROJECT_ID}-embvs-tutorial-{UID}\"\n",
    "! gsutil mb -l $LOCATION -p {PROJECT_ID} {BUCKET_URI}\n",
    "! gsutil cp questions.json {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxdbjKw1XDxl"
   },
   "source": [
    "### Create an Index\n",
    "\n",
    "Now it's ready to load the embeddings to Vector Search. Its APIs are available under the [aiplatform](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform) package of the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8unyr9KagAoI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init the aiplatform package\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpMUXqWQ75uu"
   },
   "source": [
    "Create an [MatchingEngineIndex](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex) with its `create_tree_ah_index` function (Matching Engine is the previous name of Vector Search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kKDw5VXMkXb3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/148319388360/locations/us-central1/indexes/8552348886516105216/operations/230979664686874624\n",
      "MatchingEngineIndex created. Resource name: projects/148319388360/locations/us-central1/indexes/8552348886516105216\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/148319388360/locations/us-central1/indexes/8552348886516105216')\n"
     ]
    }
   ],
   "source": [
    "# create index\n",
    "my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=f\"embvs-tutorial-index-{UID}\",\n",
    "    contents_delta_uri=BUCKET_URI,\n",
    "    dimensions=768,\n",
    "    approximate_neighbors_count=20,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rFam_w9U0dI"
   },
   "source": [
    "By calling the `create_tree_ah_index` function, it starts building an Index. This will take under a few minutes if the dataset is small, otherwise about 50 minutes or more depending on the size of the dataset. You can check status of the index creation on [the Vector Search Console > INDEXES tab](https://console.cloud.google.com/vertex-ai/matching-engine/indexes).\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/vs-quickstart/creating-index.png)\n",
    "\n",
    "#### The parameters for creating index\n",
    "\n",
    "- `contents_delta_uri`: The URI of Cloud Storage directory where you stored the embedding JSON files\n",
    "- `dimensions`: Dimension size of each embedding. In this case, it is 768 as we are using the embeddings from the Text Embeddings API.\n",
    "- `approximate_neighbors_count`: how many similar items we want to retrieve in typical cases\n",
    "- `distance_measure_type`: what metrics to measure distance/similarity between embeddings. In this case it's `DOT_PRODUCT_DISTANCE`\n",
    "\n",
    "See [the document](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index) for more details on creating Index and the parameters.\n",
    "\n",
    "#### Batch Update or Streaming Update?\n",
    "There are two types of index: Index for *Batch Update* (used in this tutorial) and Index for *Streaming Updates*. The Batch Update index can be updated with a batch process whereas the Streaming Update index can be updated in real-time. The latter one is more suited for use cases where you want to add or update each embeddings in the index more often, and crucial to serve with the latest embeddings, such as e-commerce product search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLOAMF50XMI8"
   },
   "source": [
    "### Create Index Endpoint and deploy the Index\n",
    "\n",
    "To use the Index, you need to create an [Index Endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public). It works as a server instance accepting query requests for your Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "h6IzyufWCjU1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/148319388360/locations/us-central1/indexEndpoints/8217367275951357952/operations/4579345842401443840\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/148319388360/locations/us-central1/indexEndpoints/8217367275951357952\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/148319388360/locations/us-central1/indexEndpoints/8217367275951357952')\n"
     ]
    }
   ],
   "source": [
    "# create IndexEndpoint\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=f\"embvs-tutorial-index-endpoint-{UID}\",\n",
    "    public_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial utilizes a [Public Endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/setup/setup#choose-endpoint) and does not support [Virtual Private Cloud (VPC)](https://cloud.google.com/vpc/docs/private-services-access). Unless you have a specific requirement for VPC, we recommend using a Public Endpoint. Despite the term \"public\" in its name, it does not imply open access to the public internet. Rather, it functions like other endpoints in Vertex AI services, which are secured by default through IAM. Without explicit IAM permissions, as we have previously established, no one can access the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8n33iO1T5hFO"
   },
   "source": [
    "With the Index Endpoint, deploy the Index by specifying an unique deployed index ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FcBHLifGwAWq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = f\"embvs_tutorial_deployed_{UID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1jUoGhY5TPFP",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/148319388360/locations/us-central1/indexEndpoints/8217367275951357952\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/148319388360/locations/us-central1/indexEndpoints/8217367275951357952/operations/3702129077482684416\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/148319388360/locations/us-central1/indexEndpoints/8217367275951357952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchingEngineIndexEndpoint object at 0x7fcb757037c0> \n",
       "resource name: projects/148319388360/locations/us-central1/indexEndpoints/8217367275951357952"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deploy the Index to the Index Endpoint\n",
    "my_index_endpoint.deploy_index(index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xu9ZmWcpXQ55"
   },
   "source": [
    "If it is the first time to deploy an Index to an Index Endpoint, it will take around 25 minutes to automatically build and initiate the backend for it. After the first deployment, it will finish in seconds. To see the status of the index deployment, open [the Vector Search Console > INDEX ENDPOINTS tab](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints) and click the Index Endpoint.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/github-repo/img/embeddings/vs-quickstart/deploying-index.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTi4PjjbXV-O"
   },
   "source": [
    "### Run Query\n",
    "\n",
    "Finally it's ready to use Vector Search. In the following code, it creates an embedding for a test question, and find similar question with the Vector Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FhNuRQqUWdfe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "test_embeddings = get_embeddings_wrapper([\"How to read JSON with Python?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Q01DGMBPXAg-",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265 Creating specific Json with python dictionaries\n",
      "0.7185 How to Insert array inside JSON object?\n",
      "0.7179 How to filter an array of json with jq in linux?\n",
      "0.6996 Python how to get file plot graph sine wave?\n",
      "0.6990 How I use python get opendata(xml) data\n",
      "0.6976 Circe: decoding Json field with alias, how to do it?\n",
      "0.6934 Is there a way to view a piece of data from a python script as a Linux file?\n",
      "0.6918 convert json list to a data frame in R\n",
      "0.6893 How to access attached database's tables using python's sqlite3?\n",
      "0.6891 How can I display 100 json data in HTML?\n",
      "0.6842 Error `Cannot import name 'wrappers' from 'tensorflow.python.keras.layers'`?\n",
      "0.6828 How do I show API response data in one component by calling it from another component?\n",
      "0.6792 How to use Graphviz Python module in Qgis Environment?\n",
      "0.6702 How to update MongoDB from Pandas Dataframe by using bulk operation?\n",
      "0.6697 How to base64 decode value of dynamic json array in NiFi?\n",
      "0.6697 Trouble scraping data with Beautifulsoup\n",
      "0.6685 How to access __len__() hook method inside of python class?\n",
      "0.6662 Redshift : loading & storing JSON (IoT) data\n",
      "0.6628 How to scrape a specific tag without class name?\n",
      "0.6616 Kucoin futures API [python] - \"code\":\"429000\",\"msg\":\"Too Many Requests\"\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "response = my_index_endpoint.find_neighbors(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    queries=test_embeddings,\n",
    "    num_neighbors=20,\n",
    ")\n",
    "\n",
    "# show the result\n",
    "import numpy as np\n",
    "\n",
    "for idx, neighbor in enumerate(response[0]):\n",
    "    id = np.int64(neighbor.id)\n",
    "    similar = df.query(\"id == @id\", engine=\"python\")\n",
    "    print(f\"{neighbor.distance:.4f} {similar.title.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPDOL9caoYZ9"
   },
   "source": [
    "The `find_neighbors` function only takes milliseconds to fetch the similar items even when you have billions of items on the Index, thanks to the ScaNN algorithm. Vector Search also supports [autoscaling](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#autoscaling) which can automatically resize the number of nodes based on the demands of your workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDt4D6FDyc66"
   },
   "source": [
    "# IMPORTANT: Cleaning Up\n",
    "\n",
    "In case you are using your own Cloud project, not a temporary project on Qwiklab, please make sure to delete all the Indexes, Index Endpoints and Cloud Storage buckets after finishing this tutorial. Otherwise the remaining objects would **incur unexpected costs**.\n",
    "\n",
    "If you used Workbench, you may also need to delete the Notebooks from [the console](https://console.cloud.google.com/vertex-ai/workbench)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MEsKVzguyxNx",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter to delete Index Endpoint, Index and Cloud Storage bucket: qwiklabs-gcp-04-befa2ff750b4-embvs-tutorial-07071436\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 IndexEndpoint `projects/148319388360/locations/us-central1/indexEndpoints/8217367275951357952` is not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPress Enter to delete Index Endpoint, Index and Cloud Storage bucket:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# delete Index Endpoint\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmy_index_endpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mundeploy_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m my_index_endpoint\u001b[38;5;241m.\u001b[39mdelete(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# delete Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/matching_engine/matching_engine_index_endpoint.py:1344\u001b[0m, in \u001b[0;36mMatchingEngineIndexEndpoint.undeploy_all\u001b[0;34m(self, sync)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mundeploy_all\u001b[39m(\u001b[38;5;28mself\u001b[39m, sync: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatchingEngineIndexEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Undeploys every index deployed to this MatchingEngineIndexEndpoint.\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \n\u001b[1;32m   1338\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;124;03m            be immediately returned and synced when the Future has completed.\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sync_gca_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m deployed_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployed_indexes:\n\u001b[1;32m   1347\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_undeploy(deployed_index_id\u001b[38;5;241m=\u001b[39mdeployed_index\u001b[38;5;241m.\u001b[39mid, sync\u001b[38;5;241m=\u001b[39msync)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:699\u001b[0m, in \u001b[0;36mVertexAiResourceNoun._sync_gca_resource\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sync_gca_resource\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    697\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sync GAPIC service representation of client class resource.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gca_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:692\u001b[0m, in \u001b[0;36mVertexAiResourceNoun._get_gca_resource\u001b[0;34m(self, resource_name, parent_resource_name_fields)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns GAPIC service representation of client class resource.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03m        Should not include project and location.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m resource_name \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mfull_resource_name(\n\u001b[1;32m    682\u001b[0m     resource_name\u001b[38;5;241m=\u001b[39mresource_name,\n\u001b[1;32m    683\u001b[0m     resource_noun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_noun,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m     resource_id_validator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_id_validator,\n\u001b[1;32m    690\u001b[0m )\n\u001b[0;32m--> 692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getter_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_DEFAULT_RETRY\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/index_endpoint_service/client.py:954\u001b[0m, in \u001b[0;36mIndexEndpointServiceClient.get_index_endpoint\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 IndexEndpoint `projects/148319388360/locations/us-central1/indexEndpoints/8217367275951357952` is not found."
     ]
    }
   ],
   "source": [
    "# wait for a confirmation\n",
    "input(\"Press Enter to delete Index Endpoint, Index and Cloud Storage bucket:\")\n",
    "\n",
    "# delete Index Endpoint\n",
    "my_index_endpoint.undeploy_all()\n",
    "my_index_endpoint.delete(force=True)\n",
    "\n",
    "# delete Index\n",
    "my_index.delete()\n",
    "\n",
    "# delete Cloud Storage bucket\n",
    "! gsutil rm -r {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8k26QOF3Ys7"
   },
   "source": [
    "# Summary\n",
    "\n",
    "## Grounding LLM outputs with Vertex AI Vector Search\n",
    "\n",
    "As we have seen, by combining the Embeddings API and Vector Search, you can use the embeddings to \"ground\" LLM outputs to real business data with low latency.\n",
    "\n",
    "For example, if an user asks a question, Embeddings API can convert it to an embedding, and issue an query on Vector Search to find similar embeddings in its index. Those embeddings represent the actual business data in the databases. As we are just retrieving the business data and not generating any artificial texts, there is no risk of having hallucinations in the result.\n",
    "\n",
    "![](https://storage.googleapis.com/gweb-cloudblog-publish/original_images/10._grounding.png)\n",
    "\n",
    "### The difference between the questions and answers\n",
    "\n",
    "In this tutorial, we have used the Stack Overflow dataset. There is a reason why we had to use it; As the dataset has many pairs of **questions and answers**, so you can just find questions similar to your question to find answers to it.\n",
    "\n",
    "In many business use cases, the semantics (meaning) of questions and answers are different. Also, there could be cases where you would want to add variety of recommended or personalized items to the results, like product search on e-commerce sites.\n",
    "\n",
    "In these cases, the simple semantics search don't work well. It's more like a recommendation system problem where you may want to train a model (e.g. Two-Tower model) to learn the relationship between the question embedding space and answer embedding space. Also, many production systems adds reranking phase after the semantic search to achieve higher search quality. Please see [Scaling deep retrieval with TensorFlow Recommenders and Vertex AI Matching Engine](https://cloud.google.com/blog/products/ai-machine-learning/scaling-deep-retrieval-tensorflow-two-towers-architecture) to learn more.\n",
    "\n",
    "### Hybrid of semantic + keyword search\n",
    "\n",
    "Another typical challenge you will face in production system is to support keyword search combined with the semantic search. For example, for e-commerce product search, you may want to let users find product by entering its product name or model number. As LLM doesn't memorize those product names or model numbers, semantic search can't handle those \"usual\" search functionalities.\n",
    "\n",
    "[Vertex AI Search](https://cloud.google.com/blog/products/ai-machine-learning/vertex-ai-search-and-conversation-is-now-generally-available) is another product you may consider for those requirements. While Vector Search provides a simple semantic search capability only, Search provides a integrated search solution that combines semantic search, keyword search, reranking and filtering, available as an out-of-the-box tool.\n",
    "\n",
    "### What about Retrieval Augmented Generation (RAG)?\n",
    "\n",
    "In this tutorial, we have looked at the simple combination of LLM embeddings and vector search. From this starting point, you may also extend the design to [Retrieval Augmented Generation (RAG)](https://www.google.com/search?q=Retrieval+Augmented+Generation+(RAG)&oq=Retrieval+Augmented+Generation+(RAG)).\n",
    "\n",
    "RAG is a popular architecture pattern of implementing grounding with LLM with text chat UI. The idea is to have the LLM text chat UI as a frontend for the document retrieval with vector search and summarization of the result.\n",
    "\n",
    "![](https://storage.googleapis.com/gweb-cloudblog-publish/images/Figure-7-Ask_Your_Documents_Flow.max-529x434.png)\n",
    "\n",
    "There are some pros and cons between the two solutions.\n",
    "\n",
    "| | Emb + vector search | RAG |\n",
    "|---|---|---|\n",
    "| Design | simple | complex |\n",
    "| UI | Text search UI | Text chat UI |\n",
    "| Summarization of result | No | Yes |\n",
    "| Multi-turn (Context aware) | No | Yes |\n",
    "| Latency | millisecs | seconds |\n",
    "| Cost | lower | higher |\n",
    "| Hallucinations | No risk | Some risk |\n",
    "\n",
    "The Embedding + vector search pattern we have looked at with this tutorial provides simple, fast and low cost semantic search functionality with the LLM intelligence. RAG adds context-aware text chat experience and result summarization to it. While RAG provides the more \"Gen AI-ish\" experience, it also adds a risk of hallucination and higher cost and time for the text generation.\n",
    "\n",
    "To learn more about how to build a RAG solution, you may look at [Building Generative AI applications made easy with Vertex AI PaLM API and LangChain](https://cloud.google.com/blog/products/ai-machine-learning/generative-ai-applications-with-vertex-ai-palm-2-models-and-langchain).\n",
    "\n",
    "## Resources\n",
    "\n",
    "To learn more, please check out the following resources:\n",
    "\n",
    "### Documentations\n",
    "\n",
    "[Vertex AI Embeddings for Text API documentation\n",
    "](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings)\n",
    "\n",
    "[Vector Search documentation](https://cloud.google.com/vertex-ai/docs/matching-engine/overview)\n",
    "\n",
    "### Vector Search blog posts\n",
    "\n",
    "[Vertex Matching Engine: Blazing fast and massively scalable nearest neighbor search](https://cloud.google.com/blog/products/ai-machine-learning/vertex-matching-engine-blazing-fast-and-massively-scalable-nearest-neighbor-search)\n",
    "\n",
    "[Find anything blazingly fast with Google's vector search technology](https://cloud.google.com/blog/topics/developers-practitioners/find-anything-blazingly-fast-googles-vector-search-technology)\n",
    "\n",
    "[Enabling real-time AI with Streaming Ingestion in Vertex AI](https://cloud.google.com/blog/products/ai-machine-learning/real-time-ai-with-google-cloud-vertex-ai)\n",
    "\n",
    "[Mercari leverages Google's vector search technology to create a new marketplace](https://cloud.google.com/blog/topics/developers-practitioners/mercari-leverages-googles-vector-search-technology-create-new-marketplace)\n",
    "\n",
    "[Recommending news articles using Vertex AI Matching Engine](https://cloud.google.com/blog/products/ai-machine-learning/recommending-articles-using-vertex-ai-matching-engine)\n",
    "\n",
    "[What is Multimodal Search: \"LLMs with vision\" change businesses](https://cloud.google.com/blog/products/ai-machine-learning/multimodal-generative-ai-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BE1tELsH-u8N"
   },
   "source": [
    "# Utilities\n",
    "\n",
    "Sometimes it takes tens of minutes to create or deploy Indexes and you would lose connection with the Colab runtime. In that case, instead of creating or deploying new Index again, you can check [the Vector Search Console](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints) and get the existing ones to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wF_pkdpJ-yaq"
   },
   "source": [
    "## Get an existing Index\n",
    "\n",
    "To get an Index object that already exists, replace the following `[your-index-id]` with the index ID and run the cell. You can check the ID on [the Vector Search Console > INDEXES tab](https://console.cloud.google.com/vertex-ai/matching-engine/indexes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "mEBkZZt_-0jG",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Resource [your-index-id] is not a valid resource id.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m my_index_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[your-index-id]\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# @param {type:\"string\"}\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m my_index \u001b[38;5;241m=\u001b[39m \u001b[43maiplatform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMatchingEngineIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_index_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/matching_engine/matching_engine_index.py:91\u001b[0m, in \u001b[0;36mMatchingEngineIndex.__init__\u001b[0;34m(self, index_name, project, location, credentials)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves an existing index given an index name or ID.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mExample Usage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m        credentials set in aiplatform.init.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     86\u001b[0m     project\u001b[38;5;241m=\u001b[39mproject,\n\u001b[1;32m     87\u001b[0m     location\u001b[38;5;241m=\u001b[39mlocation,\n\u001b[1;32m     88\u001b[0m     credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[1;32m     89\u001b[0m     resource_name\u001b[38;5;241m=\u001b[39mindex_name,\n\u001b[1;32m     90\u001b[0m )\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gca_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:681\u001b[0m, in \u001b[0;36mVertexAiResourceNoun._get_gca_resource\u001b[0;34m(self, resource_name, parent_resource_name_fields)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_gca_resource\u001b[39m(\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    669\u001b[0m     resource_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    670\u001b[0m     parent_resource_name_fields: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    671\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m proto\u001b[38;5;241m.\u001b[39mMessage:\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns GAPIC service representation of client class resource.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03m            Should not include project and location.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m     resource_name \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_resource_name\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_noun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_noun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_resource_name_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_resource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mformat_resource_name_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_resource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_resource_name_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_resource_name_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_id_validator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_id_validator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getter_method)(\n\u001b[1;32m    693\u001b[0m         name\u001b[38;5;241m=\u001b[39mresource_name, retry\u001b[38;5;241m=\u001b[39m_DEFAULT_RETRY\n\u001b[1;32m    694\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/utils/__init__.py:218\u001b[0m, in \u001b[0;36mfull_resource_name\u001b[0;34m(resource_name, resource_noun, parse_resource_name_method, format_resource_name_method, parent_resource_name_fields, project, location, resource_id_validator)\u001b[0m\n\u001b[1;32m    215\u001b[0m user_location \u001b[38;5;241m=\u001b[39m location \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mlocation\n\u001b[1;32m    217\u001b[0m validate_region(user_location)\n\u001b[0;32m--> 218\u001b[0m \u001b[43mresource_id_validator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m format_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_location,\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_project,\n\u001b[1;32m    223\u001b[0m     convert_camel_case_resource_noun_to_snake_case(resource_noun): resource_name,\n\u001b[1;32m    224\u001b[0m }\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parent_resource_name_fields:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/utils/__init__.py:156\u001b[0m, in \u001b[0;36mvalidate_id\u001b[0;34m(resource_id)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate resource ID.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m RESOURCE_ID_PATTERN\u001b[38;5;241m.\u001b[39mmatch(resource_id):\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResource \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid resource id.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Resource [your-index-id] is not a valid resource id."
     ]
    }
   ],
   "source": [
    "my_index_id = \"[your-index-id]\"  # @param {type:\"string\"}\n",
    "my_index = aiplatform.MatchingEngineIndex(my_index_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vlgzkyw-3CI"
   },
   "source": [
    "## Get an existing Index Endpoint\n",
    "\n",
    "To get an Index Endpoint object that already exists, replace the following `[your-index-endpoint-id]` with the Index Endpoint ID and run the cell. You can check the ID on [the Vector Search Console > INDEX ENDPOINTS tab](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0OFnirF-6Rk"
   },
   "outputs": [],
   "source": [
    "my_index_endpoint_id = \"[your-index-endpoint-id]\"  # @param {type:\"string\"}\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(my_index_endpoint_id)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
